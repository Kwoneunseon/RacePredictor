"""
ëª¨ë¸ ê´€ë¦¬ ëª¨ë“ˆ - ëª¨ë¸ ì €ì¥/ë¡œë“œ/ë²„ì „ ê´€ë¦¬
"""
import os
import json
import joblib
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging

from sklearn.preprocessing import StandardScaler, LabelEncoder
from config import MODEL_DIR, MODEL_MANAGEMENT

logger = logging.getLogger(__name__)


class ModelManager:
    """ëª¨ë¸ ì €ì¥/ë¡œë“œ/ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model_save_path:str = None):
        """
        Args:
            model_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ config ì‚¬ìš©)
        """
        self.model_save_path = model_save_path if model_save_path else MODEL_DIR
        if not os.path.exists(self.model_save_path):
            os.makedirs(self.model_save_path)
        
    
    def save_model(self, model_name="horse_racing_model", model_data:Dict = None):
        """
        í›ˆë ¨ëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ê°ì²´ë“¤ì„ ì €ì¥
        
        Args:
            model_name: ì €ì¥í•  ëª¨ë¸ ì´ë¦„
        """
        try:            
            model_path = os.path.join(self.model_save_path, f"{model_name}.pkl")
            joblib.dump(model_data, model_path)
            
            print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
            print(f"   - ëª¨ë¸ ê°œìˆ˜: {len(model_data)}")
            print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(model_data)}")
            print(f"   - ì €ì¥ ì‹œê°„: {model_data['save_date']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def load_model(self, model_name="horse_racing_model"):
        """
        ì €ì¥ëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ê°ì²´ë“¤ì„ ë¡œë“œ
        
        Args:
            model_name: ë¡œë“œí•  ëª¨ë¸ ì´ë¦„
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            model_path = os.path.join(self.model_save_path, f"{model_name}.pkl")
            
            if not os.path.exists(model_path):
                print(f"âš ï¸ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                return False
            
            model_data = joblib.load(model_path)

            self.models = model_data['models']
            self.scaler = model_data['scaler']
            self.label_encoders = model_data['label_encoders']
            self.feature_columns = model_data['feature_columns']          

            
            print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            print(f"   - ëª¨ë¸ ê°œìˆ˜: {len(self.models)}")
            print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(self.feature_columns)}")
            print(f"   - ì €ì¥ ì‹œê°„: {model_data.get('save_date', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            
            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            print(f"   - ë¡œë“œëœ ëª¨ë¸ë“¤:")
            for name, result in self.models.items():
                print(f"     * {name}: AUC={result.get('auc', 0):.3f}")
            
            return model_data
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def list_saved_models(self):
        """
        ì €ì¥ëœ ëª¨ë¸ ëª©ë¡ í™•ì¸
        """
        try:
            model_files = [f for f in os.listdir(self.model_save_path) if f.endswith('.pkl')]
            
            if not model_files:
                print("ğŸ“ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            print(f"ğŸ“ ì €ì¥ëœ ëª¨ë¸ ëª©ë¡ ({self.model_save_path}):")
            model_info = []
            
            for model_file in model_files:
                model_path = os.path.join(self.model_save_path, model_file)
                try:
                    # íŒŒì¼ ì •ë³´
                    file_stat = os.stat(model_path)
                    file_size = file_stat.st_size / (1024 * 1024)  # MB
                    modified_time = datetime.fromtimestamp(file_stat.st_mtime)
                    
                    model_info.append({
                        'file': model_file,
                        'size_mb': file_size,
                        'modified': modified_time
                    })
                    
                    print(f"  ğŸ“„ {model_file}")
                    print(f"     í¬ê¸°: {file_size:.2f}MB")
                    print(f"     ìˆ˜ì •ì¼: {modified_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    
                except Exception as e:
                    print(f"     âš ï¸ íŒŒì¼ ì •ë³´ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            return model_info
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def check_model_performance(self):
        """
        í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ì˜ ì„±ëŠ¥ í™•ì¸
        """
        if not self.models:
            print("âš ï¸ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("ğŸ“Š í˜„ì¬ ëª¨ë¸ ì„±ëŠ¥:")
        print("-" * 50)
        
        for name, result in self.models.items():
            print(f"ğŸ”¥ {name}:")
            print(f"  ì •í™•ë„: {result.get('accuracy', 0):.3f}")
            print(f"  ì •ë°€ë„: {result.get('precision', 0):.3f}")
            print(f"  ì¬í˜„ìœ¨: {result.get('recall', 0):.3f}")
            print(f"  F1: {result.get('f1', 0):.3f}")
            print(f"  AUC: {result.get('auc', 0):.3f}")
            print()
"""
ê°œì„ ëœ ëª¨ë¸ ê´€ë¦¬ ëª¨ë“ˆ - sklearn ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
"""
import os
import json
import joblib
import pickle
import shutil
import sklearn
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging
import warnings

# sklearn í˜¸í™˜ì„± ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')

from sklearn.preprocessing import StandardScaler, LabelEncoder
from config import MODEL_DIR, MODEL_MANAGEMENT

logger = logging.getLogger(__name__)


class ModelManager:
    """ëª¨ë¸ ì €ì¥/ë¡œë“œ/ê´€ë¦¬ í´ë˜ìŠ¤ (sklearn í˜¸í™˜ì„± ê°œì„ )"""
    
    def __init__(self, model_save_path: str = None):
        """
        Args:
            model_save_path: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ config ì‚¬ìš©)
        """
        self.model_save_path = model_save_path if model_save_path else MODEL_DIR
        if not os.path.exists(self.model_save_path):
            os.makedirs(self.model_save_path)
    
    def save_model_safe(self, model_name="horse_racing_model", model_data: Dict = None):
        """
        ì•ˆì „í•œ ëª¨ë¸ ì €ì¥ (sklearn í˜¸í™˜ì„± ê°œì„ )
        """
        try:
            if model_data is None:
                print("âŒ ì €ì¥í•  ëª¨ë¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # í˜„ì¬ í™˜ê²½ ì •ë³´
            env_info = {
                'sklearn_version': sklearn.__version__,
                'numpy_version': np.__version__,
                'save_timestamp': datetime.now().isoformat(),
                'python_version': f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}"
            }
            
            # ë³„ë„ë¡œ í™˜ê²½ ì •ë³´ ì €ì¥
            env_path = os.path.join(self.model_save_path, f"{model_name}_env.json")
            with open(env_path, 'w') as f:
                json.dump(env_info, f, indent=2)
            
            # ëª¨ë¸ ë°ì´í„°ì— í™˜ê²½ ì •ë³´ ì¶”ê°€
            model_data_enhanced = model_data.copy()
            model_data_enhanced.update(env_info)
            
            success_count = 0
            
            # Method 1: joblib ì €ì¥ (sklearn_version ì œí•œ)
            try:
                joblib_path = os.path.join(self.model_save_path, f"{model_name}_joblib.pkl")
                # sklearn ê°ì²´ ì €ì¥ ì‹œ í˜¸í™˜ì„± ëª¨ë“œ ì‚¬ìš©
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    joblib.dump(model_data_enhanced, joblib_path, compress=3)
                print(f"âœ… joblib ì €ì¥ ì„±ê³µ: {joblib_path}")
                success_count += 1
            except Exception as e:
                print(f"âš ï¸ joblib ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # Method 2: ì•ˆì „í•œ pickle ì €ì¥
            try:
                pickle_path = os.path.join(self.model_save_path, f"{model_name}_pickle.pkl")
                with open(pickle_path, 'wb') as f:
                    # ìµœê³  í˜¸í™˜ì„± í”„ë¡œí† ì½œ ì‚¬ìš©
                    pickle.dump(model_data_enhanced, f, protocol=4)  # python 3.4+ í˜¸í™˜
                print(f"âœ… pickle ì €ì¥ ì„±ê³µ: {pickle_path}")
                success_count += 1
            except Exception as e:
                print(f"âš ï¸ pickle ì €ì¥ ì‹¤íŒ¨: {e}")
                
            # Method 3: ëª¨ë¸ë³„ ê°œë³„ ì €ì¥ (í˜¸í™˜ì„± ìµœëŒ€í™”)
            try:
                individual_dir = os.path.join(self.model_save_path, f"{model_name}_individual")
                os.makedirs(individual_dir, exist_ok=True)
                
                # ê° êµ¬ì„± ìš”ì†Œ ê°œë³„ ì €ì¥
                if 'models' in model_data:
                    for name, model_result in model_data['models'].items():
                        model_path = os.path.join(individual_dir, f"model_{name}.pkl")
                        joblib.dump(model_result['model'], model_path)
                
                # ì „ì²˜ë¦¬ ê°ì²´ë“¤ ê°œë³„ ì €ì¥
                if 'scaler' in model_data:
                    scaler_path = os.path.join(individual_dir, "scaler.pkl")
                    joblib.dump(model_data['scaler'], scaler_path)
                
                if 'label_encoders' in model_data:
                    le_path = os.path.join(individual_dir, "label_encoders.pkl")
                    joblib.dump(model_data['label_encoders'], le_path)
                
                # ë©”íƒ€ë°ì´í„° JSON ì €ì¥
                meta_data = {k: v for k, v in model_data.items() 
                           if k not in ['models', 'scaler', 'label_encoders']}
                meta_data.update(env_info)
                
                meta_path = os.path.join(individual_dir, "metadata.json")
                with open(meta_path, 'w') as f:
                    json.dump(meta_data, f, indent=2, default=str)
                
                print(f"âœ… ê°œë³„ ì €ì¥ ì„±ê³µ: {individual_dir}")
                success_count += 1
                
            except Exception as e:
                print(f"âš ï¸ ê°œë³„ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            if success_count > 0:
                print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_name} ({success_count}ê°œ ë°©ì‹)")
                print(f"   - sklearn ë²„ì „: {env_info['sklearn_version']}")
                return True
            else:
                print(f"âŒ ëª¨ë“  ì €ì¥ ë°©ì‹ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì €ì¥ ì™„ì „ ì‹¤íŒ¨: {e}")
            return False

    def load_model_safe(self, model_name="horse_racing_model"):
        """
        ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ (sklearn í˜¸í™˜ì„± ê°œì„ )
        """
        # í™˜ê²½ ì •ë³´ ë¨¼ì € í™•ì¸
        env_path = os.path.join(self.model_save_path, f"{model_name}_env.json")
        saved_env = None
        if os.path.exists(env_path):
            try:
                with open(env_path, 'r') as f:
                    saved_env = json.load(f)
                print(f"ğŸ“‹ ì €ì¥ëœ í™˜ê²½ ì •ë³´:")
                print(f"   - sklearn: {saved_env.get('sklearn_version', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                print(f"   - í˜„ì¬ sklearn: {sklearn.__version__}")
            except:
                pass
        
        load_attempts = [
            # ì•ˆì „í•œ ìˆœì„œë¡œ ì‹œë„
            ("individual", self._load_individual_model, "ê°œë³„ êµ¬ì„±ìš”ì†Œ"),
            (f"{model_name}_pickle.pkl", self._load_with_pickle_safe, "ì•ˆì „í•œ pickle"),
            (f"{model_name}_joblib.pkl", self._load_with_joblib_safe, "ì•ˆì „í•œ joblib"),
            (f"{model_name}.pkl", self._load_with_joblib_safe, "ë ˆê±°ì‹œ")
        ]
        
        for identifier, load_func, method_name in load_attempts:
            print(f"ğŸ”„ {method_name} ë°©ì‹ìœ¼ë¡œ ë¡œë“œ ì‹œë„...")
            
            try:
                model_data = load_func(model_name if identifier == "individual" else 
                                     os.path.join(self.model_save_path, identifier))
                
                if model_data and self._validate_model_data(model_data):
                    self._apply_model_data(model_data)
                    
                    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {method_name}")
                    print(f"   - ëª¨ë¸ ê°œìˆ˜: {len(model_data.get('models', {}))}")
                    print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(model_data.get('feature_columns', []))}")
                    
                    return model_data
                    
            except Exception as e:
                print(f"âš ï¸ {method_name} ë¡œë“œ ì‹¤íŒ¨: {str(e)[:100]}...")
                continue
        
        print(f"âŒ ëª¨ë“  ë¡œë“œ ë°©ì‹ ì‹¤íŒ¨: {model_name}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨ì‹œí‚¤ì„¸ìš” (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)")
        print("2. sklearn ë²„ì „ì„ ë§ì¶°ë³´ì„¸ìš”")
        if saved_env:
            print(f"   ì €ì¥ì‹œ ë²„ì „: {saved_env.get('sklearn_version')}")
            print(f"   í˜„ì¬ ë²„ì „: {sklearn.__version__}")
        return None
    
    def _load_individual_model(self, model_name):
        """ê°œë³„ êµ¬ì„±ìš”ì†Œë¡œ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        individual_dir = os.path.join(self.model_save_path, f"{model_name}_individual")
        
        if not os.path.exists(individual_dir):
            raise FileNotFoundError("ê°œë³„ ì €ì¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        meta_path = os.path.join(individual_dir, "metadata.json")
        if not os.path.exists(meta_path):
            raise FileNotFoundError("ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        with open(meta_path, 'r') as f:
            model_data = json.load(f)
        
        # ì „ì²˜ë¦¬ ê°ì²´ë“¤ ë¡œë“œ
        scaler_path = os.path.join(individual_dir, "scaler.pkl")
        if os.path.exists(scaler_path):
            model_data['scaler'] = joblib.load(scaler_path)
        
        le_path = os.path.join(individual_dir, "label_encoders.pkl")
        if os.path.exists(le_path):
            model_data['label_encoders'] = joblib.load(le_path)
        
        # ëª¨ë¸ë“¤ ë¡œë“œ
        models = {}
        for file in os.listdir(individual_dir):
            if file.startswith("model_") and file.endswith(".pkl"):
                model_name_part = file.replace("model_", "").replace(".pkl", "")
                model_path = os.path.join(individual_dir, file)
                
                try:
                    model = joblib.load(model_path)
                    models[model_name_part] = {'model': model}
                except Exception as e:
                    print(f"âš ï¸ ëª¨ë¸ {model_name_part} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if models:
            model_data['models'] = models
            return model_data
        else:
            raise ValueError("ë¡œë“œ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
    
    def _load_with_joblib_safe(self, model_path):
        """ì•ˆì „í•œ joblib ë¡œë“œ"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            return joblib.load(model_path)
    
    def _load_with_pickle_safe(self, model_path):
        """ì•ˆì „í•œ pickle ë¡œë“œ"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            
        with open(model_path, 'rb') as f:
            return pickle.load(f)
    
    def _validate_model_data(self, model_data):
        """ëª¨ë¸ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        required_keys = ['models', 'scaler', 'label_encoders', 'feature_columns']
        
        for key in required_keys:
            if key not in model_data:
                print(f"âš ï¸ í•„ìˆ˜ í‚¤ ëˆ„ë½: {key}")
                return False
        
        if not isinstance(model_data['models'], dict) or len(model_data['models']) == 0:
            print("âš ï¸ ìœ íš¨í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        return True
    
    def _apply_model_data(self, model_data):
        """ëª¨ë¸ ë°ì´í„°ë¥¼ í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ì— ì ìš©"""
        self.models = model_data['models']
        self.scaler = model_data['scaler']
        self.label_encoders = model_data['label_encoders']
        self.feature_columns = model_data['feature_columns']
        self.best_threshold = model_data.get('best_threshold', 0.5)

    def retrain_and_save(self, train_func, model_name="horse_racing_model", **kwargs):
        """
        ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨ì‹œí‚¤ê³  ì €ì¥ (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°ìš©)
        
        Args:
            train_func: í›ˆë ¨ í•¨ìˆ˜
            model_name: ëª¨ë¸ ì´ë¦„
            **kwargs: í›ˆë ¨ í•¨ìˆ˜ì— ì „ë‹¬í•  ì¸ìë“¤
        """
        print("ğŸ”„ í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¸í•œ ëª¨ë¸ ì¬í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            # ê¸°ì¡´ ëª¨ë¸ ë°±ì—…
            backup_dir = os.path.join(self.model_save_path, "backup")
            os.makedirs(backup_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            for file in os.listdir(self.model_save_path):
                if model_name in file and file.endswith('.pkl'):
                    src = os.path.join(self.model_save_path, file)
                    dst = os.path.join(backup_dir, f"{timestamp}_{file}")
                    shutil.copy2(src, dst)
                    print(f"ğŸ“¦ ë°±ì—…: {file} -> {dst}")
            
            # ì¬í›ˆë ¨ ì‹¤í–‰
            print("ğŸƒâ€â™‚ï¸ ëª¨ë¸ ì¬í›ˆë ¨ ì¤‘...")
            model_data = train_func(**kwargs)
            
            if model_data:
                # ìƒˆë¡œìš´ í™˜ê²½ìœ¼ë¡œ ì €ì¥
                success = self.save_model_safe(model_name, model_data)
                if success:
                    print("âœ… ì¬í›ˆë ¨ ë° ì €ì¥ ì™„ë£Œ!")
                    return True
                else:
                    print("âŒ ì¬í›ˆë ¨ í›„ ì €ì¥ ì‹¤íŒ¨")
                    return False
            else:
                print("âŒ ì¬í›ˆë ¨ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ì¬í›ˆë ¨ ê³¼ì • ì‹¤íŒ¨: {e}")
            return False

    # ê¸°ì¡´ ë©”ì„œë“œë“¤...
    def save_model(self, model_name="horse_racing_model", model_data: Dict = None):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
        return self.save_model_safe(model_name, model_data)
    
    def load_model(self, model_name="horse_racing_model"):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
        return self.load_model_safe(model_name)
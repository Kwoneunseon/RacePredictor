import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from supabase import create_client, Client
import warnings
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
#import xgboost as xgb  # Added import for xgb
# algorithm1.py

from model_manager import ModelManager

warnings.filterwarnings('ignore')

class HorseRacing1stPlacePredictor:
    def __init__(self, supabase_url, supabase_key):
        """
        ê²½ë§ˆ 1ë“± ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            supabase_url: Supabase í”„ë¡œì íŠ¸ URL
            supabase_key: Supabase API í‚¤
        """
        self.supabase: Client = create_client(supabase_url, supabase_key)
        self.models = {}
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_columns = []
        self.model_manager = ModelManager()
        

    def extract_training_data_batch(self, start_date='2023-01-01', end_date='2025-03-30', batch_months=2):
        """
        ë°°ì¹˜ ì²˜ë¦¬ë¡œ í›ˆë ¨ìš© ë°ì´í„° ì¶”ì¶œ (ì›” ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬)
        """
        from datetime import datetime, timedelta
        import pandas as pd
        
        print("ğŸ“Š ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        # ë‚ ì§œ ë²”ìœ„ë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        current_date = datetime.strptime(start_date, '%Y-%m-%d')
        end_date_obj = datetime.strptime(end_date, '%Y-%m-%d')
        all_data = []
        batch_count = 0
        
        while current_date < end_date_obj:
            # ë°°ì¹˜ ë ë‚ ì§œ ê³„ì‚° (batch_months ê°œì›”ì”©)
            if batch_months == 1:
                # 1ê°œì›”ì”©
                if current_date.month == 12:
                    batch_end = current_date + relativedelta(months=1)
                else:
                    batch_end = current_date + relativedelta(months=batch_months)
            else:
                # ì§€ì •ëœ ê°œì›” ìˆ˜ë§Œí¼
                batch_end = current_date + timedelta(days=batch_months * 30)
            
            batch_end = min(batch_end, end_date_obj)
            
            batch_start_str = current_date.strftime('%Y-%m-%d')
            batch_end_str = batch_end.strftime('%Y-%m-%d')
            
            batch_count += 1
            print(f"\nğŸ”„ ë°°ì¹˜ {batch_count}: {batch_start_str} ~ {batch_end_str}")
            
            try:
                batch_data = self._extract_batch_data(batch_start_str, batch_end_str)
                if len(batch_data) > 0:
                    all_data.extend(batch_data)
                    print(f"âœ… {len(batch_data)}ê°œ ì¶”ê°€ (ì´ {len(all_data)}ê°œ)")
                else:
                    print("âš ï¸ ì´ ë°°ì¹˜ì—ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {batch_count} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                # ë” ì‘ì€ ë°°ì¹˜ë¡œ ì¬ì‹œë„
                if batch_months > 1:
                    print("ğŸ”„ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ì¬ì‹œë„...")
                    smaller_batch = self.extract_training_data_batch(
                        batch_start_str, batch_end_str, batch_months=1
                    )
                    if len(smaller_batch) > 0:
                        all_data.extend(smaller_batch)
            
            current_date = batch_end
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ì¤‘ê°„ ì €ì¥ì  ì œê³µ
            if len(all_data) > 50000:
                print(f"ğŸ—‚ï¸ ì¤‘ê°„ ì ê²€: {len(all_data)}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ë¨")
        
        if not all_data:
            print("âŒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì•ˆ ë°©ë²•ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            return self._extract_data_alternative(start_date, end_date)
        
        df = pd.DataFrame(all_data)
        print(f"âœ… ì „ì²´ {len(df)}ê°œ ë ˆì½”ë“œ ì¶”ì¶œ ì™„ë£Œ")
        
        return self._preprocess_data(df, is_training=True)

    def _extract_batch_data(self, start_date, end_date):
        """
        ë‹¨ì¼ ë°°ì¹˜ ë°ì´í„° ì¶”ì¶œ (ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬)
        """
        all_data = []
        page_size = 50  # í˜ì´ì§€ í¬ê¸° ì¤„ì„
        offset = 0
        
        while True:
            # ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬ - Window function ìµœì†Œí™”
            query = f"""
            SELECT row_to_json(r) as result
            FROM (
                SELECT *
                FROM race_analysis_complete
                WHERE final_rank IS NOT NULL 
                AND race_date BETWEEN $1::date AND $2::date
                AND prev_total_races >= 3  -- ìµœì†Œ 3ê²½ì£¼ ì´ìƒ ì¶œì „í•œ ë§ë§Œ
                ORDER BY race_date, race_id, meet_code, entry_number
                LIMIT {page_size} OFFSET {offset}
            ) r
            """
            
            try:
                result = self.supabase.rpc('execute_sql', {
                    'sql_query': query, 
                    'params': [start_date, end_date]
                }).execute()
                
                if not result.data:
                    break
                    
                page_data = [row["result"] for row in result.data]
                all_data.extend(page_data)
                
                # ë§ˆì§€ë§‰ í˜ì´ì§€ í™•ì¸
                if len(page_data) < page_size:
                    break
                    
                offset += page_size
                
            except Exception as e:
                print(f"âš ï¸ í˜ì´ì§€ {offset//page_size + 1} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                break
        
        return all_data

    
    def _extract_data_alternative(self, start_date, end_date):
        """
        RPC í•¨ìˆ˜ê°€ ì—†ì„ ë•Œ ëŒ€ì•ˆì  ë°ì´í„° ì¶”ì¶œ ë°©ë²•
        """
        print("ğŸ”„ ëŒ€ì•ˆì  ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ...")
        
        # ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ
        race_entries = self.supabase.table('race_entries')\
            .select('*, horses(*), races(*), jockeys(*), trainers(*), betting_odds(*)')\
            .gte('race_date', start_date)\
            .lte('race_date', end_date)\
            .not_.is_('final_rank', 'null')\
            .execute()
        
        if not race_entries.data:
            print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        df = pd.DataFrame(race_entries.data)
        df = self._flatten_supabase_data(df)
        df = self._calculate_features_python(df)
        
        return self._preprocess_data(df)
    
    def _flatten_supabase_data(self, df):
        """ì¤‘ì²©ëœ Supabase ë°ì´í„° í‰ë©´í™”"""
        # horses ë°ì´í„° í‰ë©´í™”
        if 'horses' in df.columns:
            horses_df = pd.json_normalize(df['horses'])
            horses_df.columns = ['horse_' + col for col in horses_df.columns]
            df = pd.concat([df.drop('horses', axis=1), horses_df], axis=1)
        
        # races ë°ì´í„° í‰ë©´í™”
        if 'races' in df.columns:
            races_df = pd.json_normalize(df['races'])
            races_df.columns = ['race_' + col for col in races_df.columns]
            df = pd.concat([df.drop('races', axis=1), races_df], axis=1)
        
        # ê¸°íƒ€ í…Œì´ë¸”ë“¤ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        for table in ['jockeys', 'trainers', 'betting_odds']:
            if table in df.columns:
                table_df = pd.json_normalize(df[table])
                table_df.columns = [table[:-1] + '_' + col for col in table_df.columns]
                df = pd.concat([df.drop(table, axis=1), table_df], axis=1)
        
        return df
    
    def _calculate_features_python(self, df):
        """Pythonìœ¼ë¡œ íŠ¹ì„± ê³„ì‚°"""
        df = df.sort_values(['horse_id', 'race_date'])
        
        # ë§ë³„ ê³¼ê±° ì„±ì  ê³„ì‚°
        df['prev_total_races'] = df.groupby('horse_id').cumcount()
        df['prev_5_avg_rank'] = df.groupby('horse_id')['final_rank'].rolling(5, min_periods=1).mean().shift(1).values
        df['prev_total_avg_rank'] = df.groupby('horse_id')['final_rank'].expanding().mean().shift(1).values
        df['prev_wins'] = df.groupby('horse_id')['final_rank'].apply(lambda x: (x == 1).cumsum().shift(1)).values
        df['prev_top3'] = df.groupby('horse_id')['final_rank'].apply(lambda x: (x <= 3).cumsum().shift(1)).values
        
        # 1ë“± ì—¬ë¶€
        df['is_winner'] = (df['final_rank'] == 1).astype(int)
        
        # ìµœì†Œ 3ê²½ì£¼ ì´ìƒ ì¶œì „í•œ ë§ë§Œ í•„í„°ë§
        df = df[df['prev_total_races'] >= 3]
        
        return df
    
    def safe_convert_to_numeric(self, df):
        """
        ëª¨ë“  object ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ ìˆ«ìë¡œ ë³€í™˜
        """
        print("ğŸ”§ ëª¨ë“  ë¬¸ìì—´ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ ì¤‘...")
        
        # íŠ¹ë³„ ë§¤í•‘ì´ í•„ìš”í•œ ì»¬ëŸ¼ë“¤
        special_mappings = {
            'budam': {
                'í•¸ë””ìº¡': 0, 
                'ë§ˆë ¹': 1, 
                'ë³„ì •a': 2, 
                'ë³„ì •b': 3, 
                'ë³„ì •c': 4, 
                'ë³„ì •d': 5,
                'nan': 0, None: 0, '': 0, 'unknown': 0
            },
            'weight_type': {
                # weight_typeì€ í•­ìƒ 2ë¼ê³  í•˜ì…¨ìœ¼ë‹ˆ ê·¸ëŒ€ë¡œ 2ë¡œ ì„¤ì •
                2: 2, '2': 2, 
                'nan': 2, None: 2, '': 2, 'unknown': 2
            }
        }        
        for col in df.columns:
            if df[col].dtype == 'object':
                print(f"  ğŸ”„ {col} ì²˜ë¦¬ ì¤‘...")
                
                # ì´ë¯¸ LabelEncoderë¡œ ì²˜ë¦¬ëœ ì»¬ëŸ¼ë“¤ì€ ê±´ë„ˆë›°ê¸°
                if col in ['horse_class', 'race_grade', 'track_condition', 'weather']:
                    continue
                
                # íŠ¹ë³„ ë§¤í•‘ì´ ìˆëŠ” ì»¬ëŸ¼
                if col in special_mappings:
                    df[col] = df[col].map(special_mappings[col]).fillna(0)
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)                    
              
        
        print("âœ… ëª¨ë“  ì»¬ëŸ¼ ìˆ«ì ë³€í™˜ ì™„ë£Œ")
        return df
    
    def _preprocess_data(self, df, is_training=False):
        """
        ë°ì´í„° ì „ì²˜ë¦¬
        Args:
            df: ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
            is_training: í•™ìŠµìš© ë°ì´í„°ì¸ì§€ ì—¬ë¶€
        """
        print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        # final_rankê°€ 16ì„ ì´ˆê³¼í•˜ëŠ” ê°’ë“¤ 16ìœ¼ë¡œ ë³€ê²½
        if 'final_rank' in df.columns:
            over_16 = df['final_rank'] > 16
            if over_16.any():
                df.loc[over_16, 'final_rank'] = 16

        if not is_training:
            columns_to_drop = ['final_rank', 'is_winner']
            for col in columns_to_drop:
                if col in df.columns:
                    df = df.drop(columns=[col])
                    print(f"  ğŸš« ì˜ˆì¸¡ ì‹œ {col} ì»¬ëŸ¼ ì œê±°")

        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
        
        # ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì²˜ë¦¬
        categorical_cols = ['horse_class', 'race_grade', 'track_condition', 'weather']
        
        if is_training:
            # í•™ìŠµ ì‹œ: unknown ë°ì´í„° ì œì™¸
            print("ğŸ“š í•™ìŠµ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            # 1. ë¨¼ì € ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°
            for col in categorical_cols:
                if col in df.columns:
                    before_len = len(df)
                    df = df.dropna(subset=[col])  # í•´ë‹¹ ì»¬ëŸ¼ì´ ê²°ì¸¡ì¸ í–‰ ì œê±°
                    after_len = len(df)
                    if before_len != after_len:
                        print(f"   {col} ê²°ì¸¡ê°’ {before_len - after_len}ê°œ í–‰ ì œê±°")
            
            # 2. LabelEncoder í•™ìŠµ (ê²°ì¸¡ê°’ ì—†ëŠ” ê¹¨ë—í•œ ë°ì´í„°ë¡œ)
            for col in categorical_cols:
                if col in df.columns:
                    df[col] = df[col].astype(str)
                    self.label_encoders[col] = LabelEncoder()
                    df[col] = self.label_encoders[col].fit_transform(df[col])
                    print(f"   {col} ì¸ì½”ë”© ì™„ë£Œ: {len(self.label_encoders[col].classes_)}ê°œ í´ë˜ìŠ¤")
            # ì´ìƒì¹˜ ì œê±°
            df = df[df['final_rank'] <= 20]
            df = df[df['total_horses'] >= 5]       
        
        else:
            # ì˜ˆì¸¡ ì‹œ: unknownìœ¼ë¡œ ì²˜ë¦¬
            print("ğŸ”® ì˜ˆì¸¡ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            for col in categorical_cols:
                if col in df.columns:
                    # 1. ê²°ì¸¡ê°’ì„ 'unknown'ìœ¼ë¡œ ì²˜ë¦¬
                    df[col] = df[col].fillna('unknown').astype(str)
                    
                    # 2. í•™ìŠµëœ LabelEncoderë¡œ ë³€í™˜
                    if col in self.label_encoders:
                        df[col] = self._safe_transform_with_unknown(df[col], col)
                    else:
                        print(f"âš ï¸ {col}ì— ëŒ€í•œ LabelEncoderê°€ ì—†ìŠµë‹ˆë‹¤!")
                        df[col] = 0  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
        
        # ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
        df['jockey_win_rate'] = df['jockey_total_wins'] / (df['jockey_total_races'] + 1)
        df['trainer_win_rate'] = df['trainer_total_wins'] / (df['trainer_total_races'] + 1)
        df['horse_win_rate'] = df['prev_wins'] / (df['prev_total_races'] + 1)
        df['horse_top3_rate'] = df['prev_top3'] / (df['prev_total_races'] + 1)
        df['experience_score'] = np.log1p(df['prev_total_races'])
        df['recent_form'] = 6 - df['prev_5_avg_rank'].fillna(6)
        

        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df


    def _safe_transform_with_unknown(self, series, column_name):
        """
        ì˜ˆì¸¡ ì‹œ ì•ˆì „í•œ ë³€í™˜ (ìƒˆë¡œìš´ ê°’ì€ unknownìœ¼ë¡œ ì²˜ë¦¬)
        """
        encoder = self.label_encoders[column_name]
        known_classes = set(encoder.classes_)
        
        # ìƒˆë¡œìš´ ê°’ë“¤ ì°¾ê¸°
        current_values = set(series.unique())
        unseen_values = current_values - known_classes
        
        if unseen_values:
            print(f"   âš ï¸ {column_name}ì—ì„œ ìƒˆë¡œìš´ ê°’ ë°œê²¬: {unseen_values}")
            
            # ìƒˆë¡œìš´ ê°’ë“¤ì„ unknownìœ¼ë¡œ ëŒ€ì²´
            series_copy = series.copy()
            for unseen_val in unseen_values:
                series_copy = series_copy.replace(unseen_val, 'unknown')
            
            # unknownë„ í•™ìŠµëœ í´ë˜ìŠ¤ì— ì—†ë‹¤ë©´ (ì´ëŸ° ê²½ìš°ëŠ” ì—†ì–´ì•¼ í•˜ì§€ë§Œ)
            if 'unknown' not in known_classes:
                # ê°€ì¥ ë¹ˆë²ˆí•œ í´ë˜ìŠ¤ë¡œ ëŒ€ì²´
                most_common = encoder.classes_[0]
                series_copy = series_copy.replace('unknown', most_common)
                print(f"   unknownì„ {most_common}ìœ¼ë¡œ ëŒ€ì²´")
        else:
            series_copy = series
        
        return encoder.transform(series_copy)
    
    def train_models(self, df, test_size=0.2, model_name='horse_racing_model'):
        """
        1ë“± ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨
        """
        print("ğŸ¤– ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        # íŠ¹ì„± ì„ íƒ
        feature_cols = [
            'horse_age', 'is_male', 'horse_class', 'race_distance', 'total_horses',
            'horse_weight', 'race_grade', 'track_condition', 'weather',
            'prev_total_races', 'prev_5_avg_rank', 'prev_total_avg_rank',
            'jockey_win_rate', 'trainer_win_rate', 'horse_win_rate', 'horse_top3_rate',
            'popularity_score', 'experience_score', 'recent_form'
        ]
        
        # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        feature_cols = [col for col in feature_cols if col in df.columns]
        self.feature_columns = feature_cols
        
        X = df[feature_cols]
        y = df['is_winner']
        
        print(f"ğŸ“‹ ì‚¬ìš© íŠ¹ì„±: {len(feature_cols)}ê°œ")
        print(f"ğŸ¯ íƒ€ê²Ÿ ë¶„í¬: 1ë“± {y.sum()}ê°œ / ì „ì²´ {len(y)}ê°œ ({y.mean()*100:.2f}%)")
        
        # ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•œ ë¶„í• 
        df_sorted = df.sort_values('race_date')
        split_idx = int(len(df_sorted) * (1 - test_size))
        
        X_train = df_sorted.iloc[:split_idx][feature_cols]
        X_test = df_sorted.iloc[split_idx:][feature_cols]
        y_train = df_sorted.iloc[:split_idx]['is_winner']
        y_test = df_sorted.iloc[split_idx:]['is_winner']
        
        # ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ì—¬ëŸ¬ ëª¨ë¸ í›ˆë ¨
        models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=500,  # 300 â†’ 500
                max_depth=15,      # 10 â†’ 15
                min_samples_split=5,   # 20 â†’ 5
                min_samples_leaf=2,    # 10 â†’ 2
                class_weight={0: 1, 1: 20},  # 10 â†’ 20
                max_features='log2',   # sqrt â†’ log2
                random_state=42
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=200, 
                max_depth=6, 
                random_state=42
            ),
            'LogisticRegression': LogisticRegression(
                random_state=42, 
                class_weight='balanced',
                max_iter=1000
            )
        }
        
        results = {}
        
        for name, model in models.items():
            print(f"\nğŸ”¥ {name} í›ˆë ¨ ì¤‘...")
            
            # í›ˆë ¨
            if name == 'LogisticRegression':
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                y_prob = model.predict_proba(X_test_scaled)[:, 1]
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                y_prob = model.predict_proba(X_test)[:, 1]
            
            # ì„±ëŠ¥ í‰ê°€
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_prob)
            
            results[name] = {
                'model': model,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'auc': auc,
                'predictions': y_pred,
                'probabilities': y_prob
            }
            
            print(f"  ì •í™•ë„: {accuracy:.3f}")
            print(f"  ì •ë°€ë„: {precision:.3f}")
            print(f"  ì¬í˜„ìœ¨: {recall:.3f}")
            print(f"  F1: {f1:.3f}")
            print(f"  AUC: {auc:.3f}")
        
        self.models = results
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        ensemble_prob = np.mean([results[name]['probabilities'] for name in results], axis=0)
        ensemble_pred = (ensemble_prob > 0.5).astype(int)
        
        ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
        ensemble_auc = roc_auc_score(y_test, ensemble_prob)
        
        print(f"\nğŸ­ ì•™ìƒë¸” ê²°ê³¼:")
        print(f"  ì •í™•ë„: {ensemble_accuracy:.3f}")
        print(f"  AUC: {ensemble_auc:.3f}")
        
        # íŠ¹ì„± ì¤‘ìš”ë„ (RandomForest ê¸°ì¤€)
        feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': results['RandomForest']['model'].feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ TOP 10:")
        for idx, row in feature_importance.head(10).iterrows():
            print(f"  {row['feature']}: {row['importance']:.3f}")

        #ëª¨ë¸ ì €ì¥
        model_data = {
            'models': self.models,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_columns': self.feature_columns,
            'save_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        save_success = self.model_manager.save_model(model_name, model_data)
        if save_success:
            print(f"âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_name}")
        else:
            print(f"âŒ ëª¨ë¸ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


        
        print(f"\nğŸ­ ì¶”ê°€: 3ë“± ì•ˆ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€")
        top3_evaluation = self.evaluate_top3_prediction(df, test_size)
        
        return {
            'test_data': df_sorted.iloc[split_idx:],
            'results': results,
            'ensemble_accuracy': ensemble_accuracy,
            'ensemble_auc': ensemble_auc,
            'feature_importance': feature_importance
        }    

    def get_loaded_model(self, model_name: str = 'horse_racing_model'):
        """
        ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ê°œì„ ëœ ë²„ì „)
        """
        print("=" * 50)
        print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì‹œë„")
        print("=" * 50)
        
        model_data = self.model_manager.load_model_safe(model_name)
        
        if not model_data:
            print(f"âŒ ëª¨ë¸ '{model_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
            print("1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸:")
            print("   predictor.model_manager.list_saved_models()")
            print("2. ìƒˆë¡œìš´ ëª¨ë¸ í›ˆë ¨:")
            print("   predictor.precision_boost_training(df)")
            return False
        
        # ëª¨ë¸ ë°ì´í„° ì ìš©
        self.models = model_data['models']
        self.scaler = model_data['scaler']
        self.label_encoders = model_data['label_encoders']
        self.feature_columns = model_data['feature_columns']
        self.best_threshold = model_data.get('best_threshold', 0.5)
        
        print(f"âœ… ëª¨ë¸ '{model_name}' ë¡œë“œ ì„±ê³µ!")
        return True
    
    def predict_race_winners(self, race_date, meet_code=None, race_no=None, show=True):
        """
        íŠ¹ì • ê²½ì£¼ì˜ 1ë“± ì˜ˆì¸¡ (ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± í¬í•¨)
        """
        print(f"ğŸ”® {race_date} ê²½ì£¼ ì˜ˆì¸¡ ì¤‘...")       

        # WHERE ì¡°ê±´ êµ¬ì„±
        where_conditions = [f"race_date = '{race_date}'"]
        if meet_code:
            where_conditions.append(f"meet_code = '{meet_code}'")
        if race_no:
            where_conditions.append(f"race_id = '{race_no}'")  # ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        
        where_clause = " AND ".join(where_conditions)
        
        # ìˆ˜ì •ëœ ì¿¼ë¦¬ - ì¤‘ë³µ ì œê±° ë° ì˜¬ë°”ë¥¸ JOIN
        query = f"""
                SELECT row_to_json(r) as result
                FROM (
                    SELECT DISTINCT
                        race_id,
                        horse_id,
                        race_date,
                        meet_code,
                        entry_number,
                        horse_weight,
                        final_rank,
                        finish_time,
                        horse_race_days,
                        horse_weight_diff,
                        budam,
                        budam_weight,
                        horse_rating, 
                        is_winner,
                        
                        -- ë§ ì •ë³´
                        horse_age,
                        is_male,
                        horse_class,
                        horse_name,

                        -- ê²½ì£¼ ì •ë³´
                        race_distance,
                        total_horses,
                        planned_horses,
                        race_grade,
                        track_condition,
                        weather,
                        weight_type,  

                        prev_total_races,
                        prev_5_avg_rank,
                        prev_total_avg_rank,

                        prev_3_avg_speed_mps, 
                        prev_5_avg_speed_mps,
                        speed_improvement_trend,
                        prev_3_avg_time_same_distance, 

                        prev_top3,
                        prev_top5,
                        year_top3,
                        year_top5,
                        total_races,
                        total_win_rate,
                        total_place_rate,
                        year_races,
                        year_win_rate,
                        year_place_rate, 

                        -- ê¸°ìˆ˜ ì •ë³´ (NULL ì²˜ë¦¬)
                        COALESCE(jockey_total_races, 0) as jockey_total_races,
                        COALESCE(jockey_total_wins, 0) as jockey_total_wins,
                        COALESCE(jockey_year_races, 0) as jockey_year_races,
                        COALESCE(jockey_year_wins, 0) as jockey_year_wins,
                        
                        -- ì¡°êµì‚¬ ì •ë³´ (NULL ì²˜ë¦¬)
                        COALESCE(trainer_total_races, 0) as trainer_total_races,
                        COALESCE(trainer_total_wins, 0) as trainer_total_wins,
                        COALESCE(trainer_year_races, 0) as trainer_year_races,
                        COALESCE(trainer_year_wins, 0) as trainer_year_wins,
                        
                        avg_rank_at_distance,
                        races_at_distance
                                            
                    FROM race_analysis_complete
                    WHERE {where_clause}
                    ORDER BY race_id, entry_number
                ) r
                """
                
        try:
            result = self.supabase.rpc('execute_sql', {
                'sql_query': query,
                'params': []
            }).execute()

            if not result.data:
                print("âŒ í•´ë‹¹ ê²½ì£¼ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
                
            df = pd.DataFrame([row["result"] for row in result.data])
            df = self.safe_convert_to_numeric(df)
            
            # ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°ì´í„°)
            df = df.drop_duplicates(subset=['race_id', 'race_date', 'meet_code', 'horse_id', 'entry_number'])
            
            print(f"ğŸ“Š ì¡°íšŒëœ ë°ì´í„°: {len(df)}ê°œ ë ˆì½”ë“œ")
            print(f"ğŸ“Š ê³ ìœ  ê²½ì£¼ ìˆ˜: {df[['race_date', 'meet_code', 'race_id']].drop_duplicates().shape[0]}ê°œ")
            print(f"ğŸ“Š ê³ ìœ  ë§ ìˆ˜: {df['horse_id'].nunique()}ê°œ")
            
            # ğŸ”§ ê° ë§ì˜ ê³¼ê±° ë°ì´í„° ê³„ì‚°
            df = self._calculate_prediction_features(df, race_date)
            
            # ğŸ¯ í•µì‹¬ ìˆ˜ì •: ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì¶”ê°€!
            print("ğŸ‡ ì˜ˆì¸¡ìš© ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì¤‘...")
            try:
                df = self.create_racing_specific_features(df)
                print("âœ… ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì‹¤íŒ¨: {e}")
                print("ê¸°ë³¸ íŠ¹ì„±ë§Œìœ¼ë¡œ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            copy_df = df.copy()
            df = self._preprocess_data(df, is_training=False)
            
            # ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì—ëŸ¬
            if not self.models:
                print("âŒ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ê±°ë‚˜ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")
                return None
            
            # í•„ìš”í•œ íŠ¹ì„±ì´ ìˆëŠ”ì§€ í™•ì¸
            missing_features = [col for col in self.feature_columns if col not in df.columns]
            if missing_features:
                print(f"âš ï¸ ëˆ„ë½ëœ íŠ¹ì„±: {missing_features}")
                print("ğŸ”§ ëˆ„ë½ëœ íŠ¹ì„±ì„ 0ìœ¼ë¡œ ì±„ì›Œì„œ ì§„í–‰í•©ë‹ˆë‹¤...")
                
                # ëˆ„ë½ëœ íŠ¹ì„±ì„ 0ìœ¼ë¡œ ì±„ìš°ê¸°
                for feature in missing_features:
                    df[feature] = 0
                
                print("âœ… ëˆ„ë½ íŠ¹ì„± ì²˜ë¦¬ ì™„ë£Œ")
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            predictions = []
            
            for name, result in self.models.items():
                model = result['model']
                
                try:
                    if name == 'LogisticRegression' or 'LR' in name:
                        X_scaled = self.scaler.transform(df[self.feature_columns])
                        prob = model.predict_proba(X_scaled)[:, 1]
                        
                    elif 'XGB' in name:
                        X_numpy = df[self.feature_columns].values
                        prob = model.predict_proba(X_numpy)[:, 1]
                    else:
                        prob = model.predict_proba(df[self.feature_columns])[:, 1]
                    
                    predictions.append(prob)
                except Exception as e:
                    print(f"âš ï¸ {name} ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                    continue
            
            if not predictions:
                print("âŒ ëª¨ë“  ëª¨ë¸ ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None
            
            # ì•™ìƒë¸” ì˜ˆì¸¡
            ensemble_prob = np.mean(predictions, axis=0)
            
            # ê²°ê³¼ ì •ë¦¬
            result_df = copy_df[['race_id', 'race_date', 'meet_code','horse_id', 'horse_name', 'entry_number', 
                        'horse_age', 'horse_class', 'is_male', 'final_rank','prev_total_races']].copy()
            result_df['win_probability'] = ensemble_prob
            
            # ê²½ì£¼ë³„ë¡œ ì˜ˆì¸¡ ë“±ìˆ˜ ê³„ì‚°
            def calculate_race_rank(group):
                group = group.copy()
                group['prediction_rank'] = group['win_probability'].rank(ascending=False, method='min').astype(int)
                return group
            
            result_df = result_df.groupby(['race_id', 'meet_code']).apply(calculate_race_rank).reset_index(drop=True)
            result_df = result_df.sort_values(['meet_code','race_id','race_date', 'prediction_rank'])

            # ğŸ¯ ì •ë°€ë„ ì¤‘ì‹¬ ì¶”ì²œ (ì„ê³„ê°’ ì ìš©)
            threshold = getattr(self, 'best_threshold', 0.5)
            result_df['high_confidence'] = (result_df['win_probability'] > threshold).astype(int)
            result_df['recommendation'] = result_df['high_confidence'].map({
                1: 'ğŸ¯ ê°•ë ¥ ì¶”ì²œ',
                0: 'âš ï¸ ë³´ë¥˜'
            })

            # ğŸ†• ê²½í—˜ ë¶€ì¡± í‘œì‹œ ì¶”ê°€
            result_df['is_inexperienced'] = (result_df['prev_total_races'] <= 5).astype(int)
            result_df['experience_flag'] = result_df['is_inexperienced'].map({
                1: 'ğŸ”° ì‹ ì°¸',  # 5ê²½ì£¼ ì´í•˜
                0: ''         # ê²½í—˜ ì¶©ë¶„
            })

            if show:
                # ê²½ì£¼ë³„ ê²°ê³¼ ì¶œë ¥
                print("\n" + "="*60)
                print("ğŸ† ì˜ˆì¸¡ ê²°ê³¼")
                print("="*60)

                unique_races = result_df[['meet_code', 'race_id']].drop_duplicates().sort_values(['meet_code','race_id'])
                
                for _, row in unique_races.iterrows():
                    race_id = row['race_id']
                    meet_code = row['meet_code']
                    race_data = result_df[(result_df['race_id'] == race_id) & (result_df['meet_code'] == meet_code)].head(3)
                    
                    print(f"\nğŸ {meet_code} ê²½ì£¼ {race_id}ë²ˆ - TOP 5 ì˜ˆì¸¡")
                    print("-" * 50)
                    
                    for idx, row in race_data.iterrows():
                        gender = 'ìˆ˜ì»·' if row['is_male'] == 1 else 'ì•”ì»·'
                        actual_rank = f" (ì‹¤ì œ: {int(row['final_rank'])}ë“±)" if pd.notna(row['final_rank']) else ""
                        confidence_icon = "ğŸ¯" if row['high_confidence'] == 1 else "âš ï¸"
                        experience_info = f" {row['experience_flag']}" if row['experience_flag'] else ""
                        experience_races = f"({int(row['prev_total_races'])}ê²½ì£¼)" if pd.notna(row['prev_total_races']) else "(ê²½í—˜ë¶ˆëª…)"
                
                        print(f"  {confidence_icon} {int(row['prediction_rank'])}ë“± | "
                            f"#{int(row['entry_number'])}ë²ˆ | "
                            f"{row['horse_name']}{experience_info} | "
                            f"{int(row['horse_age'])}ì„¸ {gender} | "
                            f"ë“±ê¸‰:{row['horse_class']} | "
                            f"í™•ë¥ :{row['win_probability']:.3f} | "
                            f"{row['recommendation']}"
                            f"{actual_rank}")

                # ê°•ë ¥ ì¶”ì²œ ìš”ì•½
                high_conf = result_df[result_df['high_confidence'] == 1]
                print(f"\nğŸ¯ ì •ë°€ë„ ì¤‘ì‹¬ ì¶”ì²œ ìš”ì•½ (ì„ê³„ê°’: {threshold:.3f}):")
                if len(high_conf) > 0:
                    print(f"ê°•ë ¥ ì¶”ì²œ: {len(high_conf)}ë§ˆë¦¬")
                    for _, horse in high_conf.iterrows():
                        print(f"  ğŸ† {horse['horse_name']} (#{horse['entry_number']}ë²ˆ, í™•ë¥ : {horse['win_probability']:.3f})")
                else:
                    print("âš ï¸ ì´ë²ˆ ê²½ì£¼ëŠ” í™•ì‹ í•  ë§Œí•œ ë§ì´ ì—†ìŠµë‹ˆë‹¤.")

                # ğŸ†• ì‹ ì°¸ ë§ ë³„ë„ ê²½ê³ 
                inexperienced_in_top3 = result_df[
                    (result_df['prediction_rank'] <= 3) & 
                    (result_df['is_inexperienced'] == 1)
                ]
                
                if len(inexperienced_in_top3) > 0:
                    print(f"\nğŸ”° ì‹ ì°¸ ë§ ì£¼ì˜ì‚¬í•­:")
                    print("-" * 30)
                    for _, horse in inexperienced_in_top3.iterrows():
                        print(f"  âš ï¸ {horse['horse_name']} (#{horse['entry_number']}ë²ˆ): "
                            f"ê³¼ê±° {int(horse['prev_total_races'])}ê²½ì£¼ë§Œ ì¶œì „ - ë³€ìˆ˜ ê°€ëŠ¥ì„± ë†’ìŒ")
                    return result_df
                    
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    # ë” ì—„ê²©í•œ í•™ìŠµ ë°ì´í„° í•„í„°ë§
    def _filter_training_data(self, df):
        """
        í•™ìŠµ ë°ì´í„°ì—ì„œ í’ˆì§ˆì´ ë‚®ì€ ë°ì´í„° ì œê±°
        """
        initial_len = len(df)
        
        # 1. í•„ìˆ˜ ì»¬ëŸ¼ë“¤ì´ ëª¨ë‘ ìˆëŠ” í–‰ë§Œ ìœ ì§€
        required_cols = ['horse_class', 'race_grade', 'track_condition', 'weather', 
                        'prev_total_races', 'jockey_total_races', 'trainer_total_races']
        
        for col in required_cols:
            if col in df.columns:
                df = df.dropna(subset=[col])
        
        # 2. ì´ìƒí•œ ê°’ë“¤ ì œê±°
        df = df[df['prev_total_races'] >= 3]  # ìµœì†Œ 3ê²½ì£¼ ì´ìƒ
        df = df[df['horse_age'] >= 2]         # 2ì„¸ ì´ìƒ
        df = df[df['horse_age'] <= 10]        # 10ì„¸ ì´í•˜
        
        print(f"ğŸ“Š ë°ì´í„° í•„í„°ë§: {initial_len} â†’ {len(df)} ({len(df)/initial_len*100:.1f}%)")
        
        return df
    
    def _calculate_prediction_features(self, df, current_date):
        """ì˜ˆì¸¡ìš© íŠ¹ì„± ê³„ì‚°"""
        print("ğŸ“Š ê° ë§ì˜ ê³¼ê±° ì„±ì  ê³„ì‚° ì¤‘...")
        
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        df['prev_total_races'] = 0
        df['prev_5_avg_rank'] = 6.0
        df['prev_total_avg_rank'] = 6.0
        df['prev_wins'] = 0
        df['prev_top3'] = 0
        df['avg_rank_at_distance'] = 6.0
        df['races_at_distance'] = 0
        
        processed_count = 0
        
        for horse_id in df['horse_id'].unique():
            try:
                # ê³¼ê±° ì„±ì  ì¡°íšŒ ì¿¼ë¦¬ (í˜„ì¬ ë‚ ì§œ ì´ì „)
                past_races = self.supabase.table('race_entries')\
                    .select('final_rank, race_date')\
                    .eq('horse_id', horse_id)\
                    .lt('race_date', current_date)\
                    .not_.is_('final_rank', 'null')\
                    .order('race_date', desc=True)\
                    .execute()
                
                if past_races.data and len(past_races.data) > 0:
                    ranks = [r['final_rank'] for r in past_races.data if r['final_rank'] is not None]
                    
                    if ranks:  # ìœ íš¨í•œ ìˆœìœ„ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
                        # íŠ¹ì„± ê³„ì‚°
                        mask = df['horse_id'] == horse_id
                        df.loc[mask, 'prev_total_races'] = len(ranks)
                        df.loc[mask, 'prev_5_avg_rank'] = np.mean(ranks[:5]) if len(ranks) >= 1 else 6.0
                        df.loc[mask, 'prev_total_avg_rank'] = np.mean(ranks) if ranks else 6.0
                        df.loc[mask, 'prev_wins'] = sum(1 for r in ranks if r == 1)
                        df.loc[mask, 'prev_top3'] = sum(1 for r in ranks if r <= 3)
                        
                        processed_count += 1
                
                # ê±°ë¦¬ë³„ ì„±ì  ê³„ì‚° (ì•ˆì „í•œ ë°©ì‹ - JOIN ì—†ì´)
                race_distance = df[df['horse_id'] == horse_id]['race_distance'].iloc[0] if len(df[df['horse_id'] == horse_id]) > 0 else None
                
                if race_distance:
                    try:
                        # 1ë‹¨ê³„: í•´ë‹¹ ë§ì˜ ëª¨ë“  ê³¼ê±° ê²½ì£¼ ID ê°€ì ¸ì˜¤ê¸°
                        past_race_entries = self.supabase.table('race_entries')\
                            .select('race_id, race_date, meet_code, final_rank')\
                            .eq('horse_id', horse_id)\
                            .lt('race_date', current_date)\
                            .not_.is_('final_rank', 'null')\
                            .execute()
                        
                        if past_race_entries.data:
                            same_distance_ranks = []
                            
                            # 2ë‹¨ê³„: ê° ê²½ì£¼ì˜ ê±°ë¦¬ ì •ë³´ ê°œë³„ ì¡°íšŒ
                            for entry in past_race_entries.data[:10]:  # ìµœê·¼ 10ê²½ì£¼ë§Œ í™•ì¸ (ì„±ëŠ¥ í–¥ìƒ)
                                try:
                                    race_info = self.supabase.table('races')\
                                        .select('race_distance')\
                                        .eq('race_id', entry['race_id'])\
                                        .eq('race_date', entry['race_date'])\
                                        .eq('meet_code', entry['meet_code'])\
                                        .execute()
                                    
                                    if (race_info.data and 
                                        race_info.data[0]['race_distance'] == race_distance):
                                        same_distance_ranks.append(entry['final_rank'])
                                        
                                except Exception as e:
                                    continue  # ê°œë³„ ì¿¼ë¦¬ ì‹¤íŒ¨ëŠ” ê±´ë„ˆë›°ê¸°
                            
                            # ê²°ê³¼ ì ìš©
                            if same_distance_ranks:
                                mask = df['horse_id'] == horse_id
                                df.loc[mask, 'avg_rank_at_distance'] = np.mean(same_distance_ranks)
                                df.loc[mask, 'races_at_distance'] = len(same_distance_ranks)
                                
                    except Exception as distance_error:
                        # ê±°ë¦¬ë³„ ì„±ì  ê³„ì‚° ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€
                        print(f"âš ï¸ ê±°ë¦¬ë³„ ì„±ì  ê³„ì‚° ì‹¤íŒ¨ (ë§ {horse_id}): {distance_error}")
                        pass
                            
            except Exception as e:
                print(f"âš ï¸ ë§ {horse_id} ê³¼ê±° ì„±ì  ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue
        
        print(f"âœ… {processed_count}/{df['horse_id'].nunique()}ë§ˆë¦¬ ê³¼ê±° ì„±ì  ê³„ì‚° ì™„ë£Œ")
        
        # ì¶”ê°€ ê¸°ë³¸ íŠ¹ì„± ìƒì„±
        df['jockey_win_rate'] = df['jockey_total_wins'] / (df['jockey_total_races'] + 1)
        df['trainer_win_rate'] = df['trainer_total_wins'] / (df['trainer_total_races'] + 1)
        df['horse_win_rate'] = df['prev_wins'] / (df['prev_total_races'] + 1)
        df['horse_top3_rate'] = df['prev_top3'] / (df['prev_total_races'] + 1)
        df['experience_score'] = np.log1p(df['prev_total_races'])
        df['recent_form'] = 6 - df['prev_5_avg_rank']
        
        # ì¸ê¸°ë„ ì ìˆ˜ (ì„ì‹œë¡œ entry_numberë¡œ ëŒ€ì²´)
        if 'popularity_score' not in df.columns:
            df['popularity_score'] = 1.0 / (df['entry_number'] + 1)
        
        return df
    
    def backtest_strategy(self, start_date, end_date, confidence_threshold=0.3):
        """
        ë°±í…ŒìŠ¤íŒ… ì „ëµ - 1ë“± ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 3ë“±ì•ˆì— ë“œëŠ”ì§€ í…ŒìŠ¤íŠ¸
        """
        print(f"ğŸ“ˆ ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰(3ë“± ì•ˆ ì˜ˆì¸¡): {start_date} ~ {end_date}")
        
        # ê¸°ê°„ë³„ ëª¨ë“  ê²½ì£¼ ì¡°íšŒ
        races = self.supabase.table('races')\
            .select('race_date, meet_code, race_id')\
            .gte('race_date', start_date)\
            .lte('race_date', end_date)\
            .execute()
        
        total_bets = 0
        total_profit = 0
        top3_hits = 0    # 3ë“± ì•ˆ ì ì¤‘
        wins = 0        # 1ë“± ì ì¤‘
        budget = 100000 # ì´ˆê¸° ì—ì‚° 10ë§Œì›

        detailed_results = [] # ìƒì„¸ê²°ê³¼ ì €ì¥
        
        for race in races.data[:50]:  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 50ê²½ì£¼ë§Œ
            try:
                predictions = self.predict_race_winners(
                    race['race_date'], 
                    race['meet_code'], 
                    race['race_id'], show=False
                )
                
                if isinstance(predictions, str) or predictions is None:
                    continue
                
                # ê°€ì¥ í™•ì‹ í•˜ëŠ” ë§ì— ë² íŒ…
                best_horse = predictions.iloc[3]
                
                # ìƒìœ„ 3ë§ˆë¦¬ ë§ ì„ íƒ (í™•ë¥  ë†’ì€ ìˆœ)
                top_picks = predictions.head(1)  # ìƒìœ„ 3ë§ˆë¦¬
            
                for idx, horse in top_picks.iterrows():
                    if horse['win_probability'] > confidence_threshold:
                        total_bets += 1
                        if horse['win_probability'] > 0.9:
                            bet_price = 10000
                        elif horse['win_probability'] > 0.8:
                            bet_price = 5000  
                        elif horse['win_probability'] > 0.7:
                            bet_price = 2000  
                        else:
                            bet_price = 1000

                        budget -= bet_price  # ë² íŒ…ê¸ˆ ì°¨ê°

                        
                        # ì‹¤ì œ ê²°ê³¼ í™•ì¸
                        actual_result = self.supabase.table('race_entries')\
                            .select('final_rank, horse_id')\
                            .eq('race_date', race['race_date'])\
                            .eq('meet_code', race['meet_code'])\
                            .eq('race_id', race['race_id'])\
                            .eq('entry_number', horse['entry_number'])\
                            .execute()
                        
                        if actual_result.data:
                            actual_rank = actual_result.data[0]['final_rank']
                            horse_id = actual_result.data[0]['horse_id']
                            
                            # ê²°ê³¼ ê¸°ë¡
                            result_record = {
                                'race_date': race['race_date'],
                                'meet_code': race['meet_code'],
                                'race_id': race['race_id'],
                                'horse_id': horse_id,
                                'entry_number': horse['entry_number'],
                                'predicted_prob': horse['win_probability'],
                                'actual_rank': actual_rank,
                                'is_top3': actual_rank <= 3,
                                'is_winner': actual_rank == 1
                            }
                            detailed_results.append(result_record)
                            
                            # 3ë“± ì•ˆì— ë“¤ì—ˆëŠ”ì§€ í™•ì¸ (ìˆ˜ì •ëœ ë¶€ë¶„)
                            if actual_rank <= 3:
                                top3_hits += 1
                                # 3ë“± ê¸°ì¤€ ìˆ˜ìµ ê³„ì‚° (ì˜ˆ: 1ë“±=3ë°°, 2ë“±=2ë°°, 3ë“±=1.5ë°°)
                                if actual_rank in [1, 2, 3]:
                                    budget += bet_price*1.6 
                                    if actual_rank == 1:
                                        wins += 1
                            
                            # ë””ë²„ê¹…ìš© ì¶œë ¥
                            status = "âœ… TOP3" if actual_rank <= 3 else "âŒ ì‹¤íŒ¨"
                            print(f" {race['race_date']} {race['meet_code']} R{race['race_id']} {horse_id}({horse['entry_number']}ë²ˆ): {horse['win_probability']:.3f} â†’ {actual_rank}ë“± {status}")
                            
                        
            except Exception as e:
                print(f"ì˜¤ë¥˜: {e}")
                continue
        
        # ê²°ê³¼ ë¶„ì„
        if total_bets > 0:
            top3_hit_rate = top3_hits / total_bets
            win_rate = wins / total_bets
            roi = (total_profit / (total_bets * 1000)) * 100
            
            print(f"\nğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ (1ë“± ëª¨ë¸ë¡œ 3ë“± ì˜ˆì¸¡):")
            print(f"  ì´ ë² íŒ…: {total_bets}íšŒ")
            print(f"  1ë“± ì ì¤‘: {wins}íšŒ ({win_rate:.1%})")
            print(f"  3ë“± ì•ˆ ì ì¤‘: {top3_hits}íšŒ ({top3_hit_rate:.1%})")
            print(f"  ë‚¨ì€ ì˜ˆì‚°: {budget}ì›")
            print(f"  ROI: {roi:.1f}%")
            
            # í™•ë¥ ë³„ ì„±ê³¼ ë¶„ì„
            print(f"\nğŸ“ˆ í™•ë¥ ëŒ€ë³„ ì„±ê³¼:")
            prob_ranges = [(0.6, 0.7), (0.7, 0.8), (0.8, 0.9), (0.9, 1.0)]
            
            for min_prob, max_prob in prob_ranges:
                range_results = [r for r in detailed_results 
                            if min_prob <= r['predicted_prob'] < max_prob]
                if range_results:
                    range_top3 = sum(1 for r in range_results if r['is_top3'])
                    range_total = len(range_results)
                    range_hit_rate = range_top3 / range_total
                    print(f"  í™•ë¥  {min_prob:.1f}~{max_prob:.1f}: {range_top3}/{range_total} ({range_hit_rate:.1%})")
            
            return {
                'total_bets': total_bets,
                'wins': wins,
                'top3_hits': top3_hits,
                'win_rate': win_rate,
                'top3_hit_rate': top3_hit_rate,
                'total_profit': total_profit,
                'roi': roi,
                'detailed_results': detailed_results
            }
        else:
            print("ë² íŒ…í•  ê²½ì£¼ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.")
            return None

    def evaluate_top3_prediction(self, df, test_size=0.2):
        """
        1ë“± í•™ìŠµ ëª¨ë¸ì˜ 3ë“± ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€
        """
        print("ğŸ¯ 3ë“± ì•ˆ ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        # ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•œ ë¶„í• 
        df_sorted = df.sort_values('race_date')
        split_idx = int(len(df_sorted) * (1 - test_size))
        
        test_df = df_sorted.iloc[split_idx:].copy()
        
        # 3ë“± ì•ˆ íƒ€ê²Ÿ ìƒì„±
        test_df['is_top3'] = (test_df['final_rank'] <= 3).astype(int)
        
        X_test = test_df[self.feature_columns]
        y_top3 = test_df['is_top3']
        y_winner = test_df['is_winner']
        
        # ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡
        print("\nğŸ“Š ëª¨ë¸ë³„ 3ë“± ì˜ˆì¸¡ ì„±ëŠ¥:")
        
        for name, result in self.models.items():
            model = result['model']
            
            if name == 'LogisticRegression':
                X_test_scaled = self.scaler.transform(X_test)
                prob = model.predict_proba(X_test_scaled)[:, 1]
            else:
                prob = model.predict_proba(X_test)[:, 1]
            
            # ë‹¤ì–‘í•œ ì„ê³„ê°’ìœ¼ë¡œ 3ë“± ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€
            thresholds =  [0.6, 0.7, 0.8, 0.9]
            
            print(f"\nğŸ”¥ {name} ëª¨ë¸:")
            for threshold in thresholds:
                pred_top3 = (prob > threshold).astype(int)
                
                # 3ë“± ì•ˆ ì˜ˆì¸¡ ì„±ëŠ¥
                from sklearn.metrics import classification_report
                top3_precision = precision_score(y_top3, pred_top3)
                top3_recall = recall_score(y_top3, pred_top3)
                top3_f1 = f1_score(y_top3, pred_top3)
                
                print(f"  ì„ê³„ê°’ {threshold}: ì •ë°€ë„={top3_precision:.3f}, ì¬í˜„ìœ¨={top3_recall:.3f}, F1={top3_f1:.3f}")
        
        return test_df
    

    # ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€í•  í†µí•© ì†”ë£¨ì…˜
    def precision_boost_training(self, df, test_size=0.2, model_name='precision_boosted_model'):
        """
        ì •ë°€ë„ ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ í†µí•© ì†”ë£¨ì…˜ (NaN ê°’ ì²˜ë¦¬ ê°œì„ )
        """
        print("ğŸš€ ì •ë°€ë„ ê·¹ëŒ€í™” ëª¨ë¸ í›ˆë ¨ ì‹œì‘!")
        df = self.safe_convert_to_numeric(df)
        
        # 1. ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„±
        print("\n1ï¸âƒ£ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„±...")
        df = self.create_racing_specific_features(df)
        
        # 2. ì—…ë°ì´íŠ¸ëœ íŠ¹ì„± ëª©ë¡
        feature_cols = [
            # ê¸°ë³¸ íŠ¹ì„±
            'horse_weight', 'horse_age', 'is_male', 'horse_class', 'race_distance', 
            'finish_time', 'horse_race_days', 'horse_weight_diff', 'budam', 'budam_weight', 'horse_rating', 
            'race_distance', 'total_horses', 'planned_horses', 'race_grade', 'track_condition', 'weather', 'weight_type',
            'prev_total_races', 'prev_5_avg_rank', 'prev_total_avg_rank',
            'prev_3_avg_speed_mps', 'prev_5_avg_speed_mps', 'speed_improvement_trend', 'prev_3_avg_time_same_distance', 

            'prev_top3', 'prev_top5',
            'year_top3', 'year_top5',
            'total_races', 'total_win_rate', 'total_place_rate',        
            'year_races', 'year_win_rate', 'year_place_rate',     

            'jockey_total_races', 'jockey_total_wins', 'jockey_year_races', 'jockey_year_wins',
            'trainer_total_races', 'trainer_total_wins', 'trainer_year_races', 'trainer_year_wins',
            'avg_rank_at_distance', 'races_at_distance',

            'horse_top3_rate','experience_score', 'recent_form',
            
            # ğŸ¯ ìƒˆë¡œìš´ í•µì‹¬ íŠ¹ì„±ë“¤
            'championship_probability',  # ê°€ì¥ ì¤‘ìš”!
            'dominance_score',
            'consistency_score', 
            'distance_fitness',
            'jockey_horse_synergy',
            'momentum',
            'championship_rank',
            'is_clear_favorite',
            'distance_performance_score', 'time_advantage_score', 
            'speed_competitiveness', 'practical_racing_score'
            'relative_win_rate'
        ]
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        feature_cols = [col for col in feature_cols if col in df.columns]
        self.feature_columns = feature_cols
        
        print(f"ğŸ“‹ ì´ íŠ¹ì„± ìˆ˜: {len(feature_cols)}ê°œ")
        
        # 3. ë°ì´í„° ë¶„í• 
        df_sorted = df.sort_values('race_date')
        split_idx = int(len(df_sorted) * (1 - test_size))
        
        X_train = df_sorted.iloc[:split_idx][feature_cols]
        X_test = df_sorted.iloc[split_idx:][feature_cols]
        y_train = df_sorted.iloc[:split_idx]['is_winner']
        y_test = df_sorted.iloc[split_idx:]['is_winner']
        
        print(f"\nğŸ“Š ë¶„í•  ì „ ë°ì´í„° ìƒíƒœ:")
        print(f"  í›ˆë ¨ ì„¸íŠ¸: 1ë“± {y_train.sum()}ê°œ / ì „ì²´ {len(y_train)}ê°œ ({y_train.mean()*100:.2f}%)")
        print(f"  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 1ë“± {y_test.sum()}ê°œ / ì „ì²´ {len(y_test)}ê°œ ({y_test.mean()*100:.2f}%)")
        
        # ğŸ”§ 4. NaN ê°’ ì™„ì „ ì œê±° (SMOTE ì ìš© ì „ í•„ìˆ˜!)
        print("\n2ï¸âƒ£ NaN ê°’ ì™„ì „ ì œê±° ì¤‘...")
        
        print(f"  ì œê±° ì „: X_train shape = {X_train.shape}")
        print(f"  NaN ê°’ ê°œìˆ˜: {X_train.isnull().sum().sum()}ê°œ")
        
        # ë°©ë²• 1: NaNì´ ìˆëŠ” í–‰ ì™„ì „ ì œê±°
        nan_mask = X_train.isnull().any(axis=1)
        clean_indices = ~nan_mask
        
        X_train_clean = X_train[clean_indices]
        y_train_clean = y_train[clean_indices]
        
        print(f"  ì œê±° í›„: X_train shape = {X_train_clean.shape}")
        print(f"  ì œê±°ëœ í–‰: {nan_mask.sum()}ê°œ")
        print(f"  ë‚¨ì€ NaN ê°œìˆ˜: {X_train_clean.isnull().sum().sum()}ê°œ")
        
        # ë§Œì•½ ì—¬ì „íˆ NaNì´ ìˆë‹¤ë©´ 0ìœ¼ë¡œ ëŒ€ì²´
        if X_train_clean.isnull().sum().sum() > 0:
            print("  âš ï¸ ì—¬ì „íˆ NaNì´ ìˆì–´ì„œ 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            X_train_clean = X_train_clean.fillna(0)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        X_test_clean = X_test.fillna(0)
        
        print(f"  ìµœì¢… í›ˆë ¨ ë°ì´í„°: {X_train_clean.shape}, NaN: {X_train_clean.isnull().sum().sum()}ê°œ")
        print(f"  ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_clean.shape}, NaN: {X_test_clean.isnull().sum().sum()}ê°œ")
        
        # 5. SMOTE ì ìš© (ì´ì œ ì•ˆì „í•¨)
        print("\n3ï¸âƒ£ SMOTEë¡œ ë°ì´í„° ê· í˜• ì¡°ì •...")
        from imblearn.over_sampling import SMOTE
        
        # SMOTE ì ìš© ì „ ë§ˆì§€ë§‰ ê²€ì¦
        assert X_train_clean.isnull().sum().sum() == 0, "ì—¬ì „íˆ NaN ê°’ì´ ìˆìŠµë‹ˆë‹¤!"
        assert not X_train_clean.isin([np.inf, -np.inf]).any().any(), "ë¬´í•œëŒ€ ê°’ì´ ìˆìŠµë‹ˆë‹¤!"
        
        smote = SMOTE(
            sampling_strategy=0.15,  # 1ë“±ì„ 15%ê¹Œì§€
            random_state=42,
            k_neighbors=min(3, y_train_clean.sum() - 1)  # 1ë“± ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ì‘ê²Œ
        )
        
        try:
            X_train_balanced, y_train_balanced = smote.fit_resample(X_train_clean, y_train_clean)
            print(f"  âœ… SMOTE ì„±ê³µ!")
            print(f"  SMOTE í›„: 1ë“± {y_train_balanced.sum()}ê°œ / ì „ì²´ {len(y_train_balanced)}ê°œ ({y_train_balanced.mean()*100:.2f}%)")
        except Exception as e:
            print(f"  âŒ SMOTE ì‹¤íŒ¨: {e}")
            print("  ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            X_train_balanced = X_train_clean
            y_train_balanced = y_train_clean
        
        # 6. ìŠ¤ì¼€ì¼ë§
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_balanced)
        X_test_scaled = scaler.transform(X_test_clean)
        
        # 7. ì •ë°€ë„ ìµœì í™” ëª¨ë¸ë“¤
        print("\n4ï¸âƒ£ ì •ë°€ë„ ìµœì í™” ëª¨ë¸ í›ˆë ¨...")
        
        # XGBoost import ì¶”ê°€
        try:
            import xgboost as xgb
            xgb_available = True
        except ImportError:
            print("  âš ï¸ XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì œì™¸ë©ë‹ˆë‹¤.")
            xgb_available = False
        
        models = {
            # ğŸ¯ ì •ë°€ë„ íŠ¹í™” RandomForest
            'PrecisionRF': RandomForestClassifier(
                n_estimators=300,
                max_depth=10,
                min_samples_split=20,
                min_samples_leaf=10,
                class_weight={0: 1, 1: 10},
                max_features='sqrt',
                random_state=42
            ),
            
            # ğŸ¯ ë³´ìˆ˜ì  ë¡œì§€ìŠ¤í‹± íšŒê·€
            'PrecisionLR': LogisticRegression(
                class_weight={0: 1, 1: 15},
                C=0.05,
                max_iter=2000,
                random_state=42
            )
        }
        
        # XGBoostê°€ ìˆì„ ë•Œë§Œ ì¶”ê°€
        if xgb_available:
            models['PrecisionXGB'] = xgb.XGBClassifier(
                n_estimators=200,  # ì¤„ì„
                max_depth=4,
                learning_rate=0.05,
                subsample=0.8,
                colsample_bytree=0.8,
                scale_pos_weight=8,
                random_state=42,
                eval_metric='logloss',  # ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
                use_label_encoder=False  # ê²½ê³  ë°©ì§€
            )
        
        results = {}
        
        for name, model in models.items():
            print(f"\nğŸ”¥ {name} í›ˆë ¨ ì¤‘...")
            
            try:
                # í›ˆë ¨
                if 'XGB' in name and xgb_available:
                    # DataFrameì„ numpy arrayë¡œ ë³€í™˜
                    X_train_xgb = X_train_balanced.values
                    X_test_xgb = X_test_clean.values
                    
                    try:
                        # eval_set ì‚¬ìš© ì‹œë„
                        model.fit(
                            X_train_xgb, y_train_balanced,
                            eval_set=[(X_test_xgb, y_test)],  # numpyë¡œ ë³€í™˜ëœ ë°ì´í„° ì‚¬ìš©
                            verbose=False
                        )
                    except (TypeError, AttributeError):
                        # ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
                        model.fit(X_train_xgb, y_train_balanced)
                    
                    y_pred = model.predict(X_test_xgb)  # numpy ì‚¬ìš©
                    y_prob = model.predict_proba(X_test_xgb)[:, 1]  # numpy ì‚¬ìš©
                elif 'LR' in name:
                    model.fit(X_train_scaled, y_train_balanced)
                    y_pred = model.predict(X_test_scaled)
                    y_prob = model.predict_proba(X_test_scaled)[:, 1]
                    
                else:  # RandomForest
                    model.fit(X_train_balanced, y_train_balanced)
                    y_pred = model.predict(X_test_clean)
                    y_prob = model.predict_proba(X_test_clean)[:, 1]
                
                # ì„±ëŠ¥ í‰ê°€
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                f1 = f1_score(y_test, y_pred, zero_division=0)
                auc = roc_auc_score(y_test, y_prob)
                
                results[name] = {
                    'model': model,
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'auc': auc,
                    'probabilities': y_prob
                }
                
                print(f"  ì •í™•ë„: {accuracy:.3f}")
                print(f"  ì •ë°€ë„: {precision:.3f} â­â­â­")
                print(f"  ì¬í˜„ìœ¨: {recall:.3f}")
                print(f"  F1: {f1:.3f}")
                
            except Exception as e:
                print(f"  âŒ {name} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
                continue
        
        if not results:
            print("âŒ ëª¨ë“  ëª¨ë¸ í›ˆë ¨ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None
        
        # 8. ì•™ìƒë¸” ë° ì„ê³„ê°’ ìµœì í™”
        print("\n5ï¸âƒ£ ì •ë°€ë„ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì•™ìƒë¸”...")
        
        # ì •ë°€ë„ê°€ ë†’ì€ ëª¨ë¸ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        precision_scores = [results[name]['precision'] for name in results]
        
        if max(precision_scores) > 0:
            max_precision = max(precision_scores)
            weights = []
            for p in precision_scores:
                weight = (p / max_precision) ** 2 if p > 0 else 0.1
                weights.append(weight)
            weights = np.array(weights) / np.sum(weights)
        else:
            weights = np.ones(len(precision_scores)) / len(precision_scores)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        ensemble_prob = np.average(
            [results[name]['probabilities'] for name in results],
            axis=0,
            weights=weights
        )
        
        # ìµœì  ì„ê³„ê°’ ì°¾ê¸°
        best_threshold = 0.5
        best_precision = 0
        
        for threshold in np.arange(0.3, 0.9, 0.02):
            pred = (ensemble_prob > threshold).astype(int)
            if pred.sum() > 0:
                prec = precision_score(y_test, pred, zero_division=0)
                if prec > best_precision:
                    best_precision = prec
                    best_threshold = threshold
        
        ensemble_pred = (ensemble_prob > best_threshold).astype(int)
        ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
        ensemble_precision = precision_score(y_test, ensemble_pred, zero_division=0)
        ensemble_recall = recall_score(y_test, ensemble_pred, zero_division=0)
        ensemble_f1 = f1_score(y_test, ensemble_pred, zero_division=0)
        
        print(f"\nğŸ­ ìµœì í™”ëœ ì•™ìƒë¸” ê²°ê³¼:")
        print(f"  ìµœì  ì„ê³„ê°’: {best_threshold:.3f}")
        print(f"  ì •í™•ë„: {ensemble_accuracy:.3f}")
        print(f"  ì •ë°€ë„: {ensemble_precision:.3f} ğŸ¯ğŸ¯ğŸ¯")
        print(f"  ì¬í˜„ìœ¨: {ensemble_recall:.3f}")
        print(f"  F1: {ensemble_f1:.3f}")
        
        # 9. ëª¨ë¸ ì €ì¥
        self.models = results
        self.scaler = scaler
        self.best_threshold = best_threshold
        
        # ModelManagerë¥¼ í†µí•œ ì•ˆì „í•œ ì €ì¥
        model_data = {
            'models': self.models,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_columns': self.feature_columns,
            'best_threshold': self.best_threshold,
            'save_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        success = self.model_manager.save_model_safe(model_name, model_data)
        if success:
            print(f"ğŸ’¾ ëª¨ë¸ì´ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_name}")
        else:
            print(f"âš ï¸ ëª¨ë¸ ì €ì¥ì— ì‹¤íŒ¨í–ˆì§€ë§Œ ë©”ëª¨ë¦¬ì—ëŠ” ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        print(f"\nâœ… ì •ë°€ë„ ê·¹ëŒ€í™” ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        print(f"ğŸ¯ ìµœì¢… ì •ë°€ë„: {ensemble_precision:.1%}")
        
        return {
            'results': results,
            'ensemble_precision': ensemble_precision,
            'ensemble_accuracy': ensemble_accuracy,
            'best_threshold': best_threshold,
            'weights': dict(zip(results.keys(), weights.round(3)))
        }

    # ì˜ˆì¸¡ í•¨ìˆ˜ë„ ì—…ë°ì´íŠ¸
    def predict_with_precision_focus(self, race_date, meet_code=None, race_no=None):
        """
        ì •ë°€ë„ ì¤‘ì‹¬ ì˜ˆì¸¡ (ë³´ìˆ˜ì  ì ‘ê·¼)
        """
        # ê¸°ì¡´ ì˜ˆì¸¡ ë¡œì§ ì‹¤í–‰
        result_df = self.predict_race_winners(race_date, meet_code, race_no)
        
        if result_df is None:
            return None
        
        # ë³´ìˆ˜ì  ì„ê³„ê°’ ì ìš©
        threshold = getattr(self, 'best_threshold', 0.6)
        result_df['high_confidence'] = (result_df['win_probability'] > threshold).astype(int)
        result_df['recommendation'] = result_df['high_confidence'].map({
            1: 'ğŸ¯ ê°•ë ¥ ì¶”ì²œ',
            0: 'âš ï¸ ë³´ë¥˜'
        })
        
        print(f"\nğŸ¯ ì •ë°€ë„ ì¤‘ì‹¬ ì¶”ì²œ (ì„ê³„ê°’: {threshold:.3f}):")
        high_conf = result_df[result_df['high_confidence'] == 1]
        
        if len(high_conf) > 0:
            print(f"ê°•ë ¥ ì¶”ì²œ: {len(high_conf)}ë§ˆë¦¬")
            for _, horse in high_conf.iterrows():
                print(f"  ğŸ† {horse['horse_name']} (í™•ë¥ : {horse['win_probability']:.3f})")
        else:
            print("âš ï¸ ì´ë²ˆ ê²½ì£¼ëŠ” í™•ì‹ í•  ë§Œí•œ ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return result_df
    
    # ê¸°ì¡´ HorseRacing1stPlacePredictor í´ë˜ìŠ¤ì— ì¶”ê°€í•  í•¨ìˆ˜

    def create_racing_specific_features(self, df):
        """
        ê²½ë§ˆì— íŠ¹í™”ëœ ê³ ê¸‰ íŠ¹ì„± ìƒì„± (ì •ë°€ë„ í–¥ìƒì— í•µì‹¬)
        """
        print("ğŸ‡ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # 1. ğŸ¯ ìƒëŒ€ì  ê²½ìŸë ¥ (ê²½ì£¼ ë‚´ì—ì„œì˜ ìƒëŒ€ì  ìœ„ì¹˜)
        def calculate_relative_strength(group):
            # ê²½ì£¼ ë‚´ì—ì„œ ê° ë§ì˜ ìƒëŒ€ì  ì‹¤ë ¥
            group['relative_experience'] = (group['prev_total_races'] - group['prev_total_races'].mean()) / (group['prev_total_races'].std() + 1)
            group['relative_win_rate'] = (group['horse_win_rate'] - group['horse_win_rate'].mean()) / (group['horse_win_rate'].std() + 0.01)
            group['relative_recent_form'] = (group['recent_form'] - group['recent_form'].mean()) / (group['recent_form'].std() + 0.1)
            
            # ê²½ì£¼ ë‚´ ë­í‚¹ (1ë“± ê°€ëŠ¥ì„±ì´ ë†’ì„ìˆ˜ë¡ ë‚®ì€ ìˆ«ì)
            group['experience_rank_in_race'] = group['prev_total_races'].rank(ascending=False, method='min')
            group['win_rate_rank_in_race'] = group['horse_win_rate'].rank(ascending=False, method='min')
            group['recent_form_rank_in_race'] = group['recent_form'].rank(ascending=False, method='min')
            
            return group
        
        df = df.groupby(['race_date', 'meet_code', 'race_id']).apply(calculate_relative_strength).reset_index(drop=True)
        
        # 2. ğŸ¯ ì¢…í•© ìš°ìœ„ ì§€ìˆ˜ (ê°€ì¥ ì¤‘ìš”!)
        df['dominance_score'] = (
            (df['relative_win_rate'] * 0.4) +           # ìŠ¹ë¥ ì´ ê°€ì¥ ì¤‘ìš”
            (df['relative_recent_form'] * 0.3) +        # ìµœê·¼ í¼
            (df['relative_experience'] * 0.2) +         # ê²½í—˜
            (-df['entry_number'] / df['total_horses'] * 0.1)  # ì¶œì „ ë²ˆí˜¸ (ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬)
        )
        
        # 3. ğŸ¯ ì¼ê´€ì„± ì§€ìˆ˜ (ì•ˆì •ì ì¸ ë§ì¼ìˆ˜ë¡ 1ë“± ê°€ëŠ¥ì„± ë†’ìŒ)
        df['consistency_score'] = np.where(
            df['prev_total_races'] >= 5,
            1 / (df['prev_total_avg_rank'].fillna(6) + 0.1),  # í‰ê·  ìˆœìœ„ê°€ ì¢‹ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            0.1  # ê²½í—˜ ë¶€ì¡±í•˜ë©´ ë‚®ì€ ì ìˆ˜
        )
        
        # 4. ğŸ¯ ê±°ë¦¬ ì í•©ì„± (ê°„ë‹¨ ë²„ì „)
        df['distance_fitness'] = np.where(
            df['races_at_distance'].fillna(0) >= 2,
            1 / (df['avg_rank_at_distance'].fillna(6) + 0.1),
            0.5  # í•´ë‹¹ ê±°ë¦¬ ê²½í—˜ ì—†ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
        )
        
        # 5. ğŸ¯ ê¸°ìˆ˜-ë§ ê¶í•© (ê¸°ìˆ˜ ìŠ¹ë¥ ë¡œ ëŒ€ì²´)
        df['jockey_horse_synergy'] = df['jockey_win_rate']
        
        # 6. ğŸ¯ ì»¨ë””ì…˜ ì§€í‘œ (ìµœê·¼ ì„±ì  ê¸°ë°˜)
        df['momentum'] = np.where(
            df['prev_5_avg_rank'].notna(),
            (6 - df['prev_5_avg_rank']) / 2,  # ìµœê·¼ 5ê²½ì£¼ ì„±ì ì„ ëª¨ë©˜í…€ìœ¼ë¡œ ë³€í™˜
            0
        )
        
        # 7. ğŸ¯ ìµœì¢… ìš°ìŠ¹ í™•ë¥  ì ìˆ˜ (ëª¨ë“  ìš”ì†Œ ì¢…í•©)
        df['championship_probability'] = (
            df['dominance_score'] * 0.25 +
            df['consistency_score'] * 0.20 +
            df['distance_fitness'] * 0.15 +
            df['jockey_horse_synergy'] * 0.15 +
            (df['momentum'] / 3 + 0.33) * 0.10 +  # ì •ê·œí™”
            df['horse_win_rate'] * 0.15
        )


        # 1. ê±°ë¦¬ë³„ ì„±ëŠ¥ ì ìˆ˜ (ê°€ì¥ ì¤‘ìš”!)
        df['distance_performance_score'] = np.where(
            df['races_at_distance'] >= 2,
            (6 - df['avg_rank_at_distance'].fillna(6)) / 5 * np.log1p(df['races_at_distance']),
            0.1
        )

        # 2. ë™ì¼ê±°ë¦¬ ì‹œê°„ ìƒëŒ€ì  ìš°ìœ„
        def calc_time_advantage(group):
            if 'prev_3_avg_time_same_distance' in group.columns:
                # ì‹œê°„ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ì—­ìˆœ ë­í‚¹
                group['time_rank_in_race'] = group['prev_3_avg_time_same_distance'].rank(method='min')
                group['time_advantage_score'] = (len(group) + 1 - group['time_rank_in_race']) / len(group)
            else:
                group['time_advantage_score'] = 0.5
            return group

        df = df.groupby(['race_date', 'meet_code', 'race_id']).apply(calc_time_advantage).reset_index(drop=True)

        # 3. ì†ë„ ê¸°ë°˜ ê²½ìŸë ¥
        df['speed_competitiveness'] = np.where(
            df['prev_3_avg_speed_mps'] > 0,
            df['prev_3_avg_speed_mps'] * (1 + df['distance_performance_score']),
            0
        )

        # 4. ì¢…í•© ì‹¤ì „ ì ìˆ˜ (í•µì‹¬!)
        df['practical_racing_score'] = (
            df['distance_performance_score'] * 0.4 +
            df['time_advantage_score'] * 0.3 +
            (df['speed_competitiveness'] / (df['speed_competitiveness'].max() + 0.1)) * 0.3
        )
        
        # 8. ğŸ¯ ê²½ì£¼ë³„ ìƒëŒ€ ìˆœìœ„ (ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±!)
        def assign_race_rankings(group):
            group['championship_rank'] = group['championship_probability'].rank(ascending=False, method='min')
            group['is_top_candidate'] = (group['championship_rank'] <= 3).astype(int)
            group['is_clear_favorite'] = (group['championship_rank'] == 1).astype(int)
            return group
        
        df = df.groupby(['race_date', 'meet_code', 'race_id']).apply(assign_race_rankings).reset_index(drop=True)
        
        # ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ ì¶”ê°€
        new_features = [
            'dominance_score', 'consistency_score', 'distance_fitness', 
            'jockey_horse_synergy', 'momentum', 'championship_probability',
            'championship_rank', 'is_top_candidate', 'is_clear_favorite',
            'relative_win_rate', 'relative_recent_form', 'win_rate_rank_in_race'
            'distance_performance_score', 'time_advantage_score', 
            'speed_competitiveness', 'practical_racing_score'
        ]
        
        print(f"âœ… {len(new_features)}ê°œ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        print("ğŸ¯ í•µì‹¬ íŠ¹ì„±: championship_probability, dominance_score, is_clear_favorite")
        
        return df
    def list_available_models(self):
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        """
        return self.model_manager.list_saved_models()

    def check_current_model_performance(self):
        """
        í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸
        """
        return self.model_manager.check_model_performance()

    def cleanup_old_models(self, keep_latest=3):
        """
        ì˜¤ë˜ëœ ëª¨ë¸ íŒŒì¼ ì •ë¦¬
        """
        return self.model_manager.cleanup_old_models(keep_latest)

    def export_model_summary(self, output_file="model_summary.json"):
        """
        ëª¨ë¸ ìš”ì•½ ì •ë³´ ë‚´ë³´ë‚´ê¸°
        """
        return self.model_manager.export_model_info(output_file)
    
    
    # ìƒì„¸ NaN ë¶„ì„ í•¨ìˆ˜ë“¤

    def analyze_nan_details(self, df):
        """
        NaN ë°ì´í„° ìƒì„¸ ë¶„ì„
        """
        print("ğŸ” NaN ë°ì´í„° ìƒì„¸ ë¶„ì„")
        print("=" * 80)
        
        # 1. ì „ì²´ í˜„í™©
        total_cells = len(df) * len(df.columns)
        nan_cells = df.isnull().sum().sum()
        print(f"ğŸ“Š ì „ì²´ í˜„í™©:")
        print(f"  ë°ì´í„° í¬ê¸°: {df.shape}")
        print(f"  ì „ì²´ ì…€: {total_cells:,}ê°œ")
        print(f"  NaN ì…€: {nan_cells:,}ê°œ ({nan_cells/total_cells*100:.2f}%)")
        
        # 2. ì»¬ëŸ¼ë³„ NaN ìƒì„¸ ë¶„ì„
        print(f"\nğŸ“‹ ì»¬ëŸ¼ë³„ NaN ìƒì„¸ ë¶„ì„:")
        print("=" * 80)
        
        nan_summary = []
        for col in df.columns:
            nan_count = df[col].isnull().sum()
            if nan_count > 0:
                nan_percentage = (nan_count / len(df)) * 100
                
                # ë°ì´í„° íƒ€ì… í™•ì¸
                dtype = str(df[col].dtype)
                
                # ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜ (NaN ì œì™¸)
                unique_count = df[col].nunique()
                
                # ìƒ˜í”Œ ê°’ë“¤ (NaN ì•„ë‹Œ ê²ƒë“¤)
                sample_values = df[col].dropna().head(3).tolist()
                
                nan_summary.append({
                    'column': col,
                    'nan_count': nan_count,
                    'nan_percentage': nan_percentage,
                    'dtype': dtype,
                    'unique_count': unique_count,
                    'sample_values': sample_values
                })
        
        # NaN ë¹„ìœ¨ë¡œ ì •ë ¬
        nan_summary.sort(key=lambda x: x['nan_percentage'], reverse=True)
        
        for info in nan_summary:
            print(f"\nğŸ”¹ {info['column']}")
            print(f"   NaN: {info['nan_count']:,}ê°œ ({info['nan_percentage']:.1f}%)")
            print(f"   íƒ€ì…: {info['dtype']}")
            print(f"   ìœ ë‹ˆí¬ê°’: {info['unique_count']:,}ê°œ")
            print(f"   ìƒ˜í”Œ: {info['sample_values']}")
        
        # 3. ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        print(f"\nğŸ·ï¸ ì¹´í…Œê³ ë¦¬ë³„ NaN ë¶„ì„:")
        print("=" * 80)
        
        categories = {
            'ğŸ†• API ì‹ ê·œ ì»¬ëŸ¼': [
                'recent_race_rating', 'recent_horse_weight', 'recent_burden_weight',
                'api_total_races', 'api_total_wins', 'api_total_places',
                'api_total_win_rate', 'api_total_place_rate',
                'api_year_races', 'api_year_wins', 'api_year_win_rate', 'api_year_place_rate'
            ],
            'ğŸ‡ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„±': [
                'championship_probability', 'dominance_score', 'consistency_score',
                'distance_fitness', 'jockey_horse_synergy', 'momentum',
                'championship_rank', 'is_clear_favorite', 'relative_win_rate'
            ],
            'ğŸ“Š ê³¼ê±° ì„±ì ': [
                'prev_total_races', 'prev_5_avg_rank', 'prev_total_avg_rank',
                'prev_wins', 'prev_top3', 'avg_rank_at_distance', 'races_at_distance'
            ],
            'ğŸ‘¤ ê¸°ìˆ˜/ì¡°êµì‚¬': [
                'jockey_total_races', 'jockey_total_wins', 'jockey_year_races', 'jockey_year_wins',
                'trainer_total_races', 'trainer_total_wins', 'trainer_year_races', 'trainer_year_wins'
            ],
            'ğŸ ê¸°ë³¸ ì •ë³´': [
                'horse_weight', 'horse_age', 'is_male', 'horse_class', 'race_distance',

                'total_horses','race_grade', 'track_condition', 'weather'
            ]
        }
        
        for category, cols in categories.items():
            category_cols = [col for col in cols if col in df.columns]
            if category_cols:
                category_nan = sum(df[col].isnull().sum() for col in category_cols)
                category_total = len(df) * len(category_cols)
                
                print(f"\n{category}:")
                print(f"  ì „ì²´ NaN: {category_nan:,}/{category_total:,} ({category_nan/category_total*100:.1f}%)")
                
                for col in category_cols:
                    if col in df.columns:
                        nan_count = df[col].isnull().sum()
                        if nan_count > 0:
                            print(f"    âŒ {col}: {nan_count:,}ê°œ ({nan_count/len(df)*100:.1f}%)")
                        else:
                            print(f"    âœ… {col}: 0ê°œ")
        
        # 4. NaN íŒ¨í„´ ë¶„ì„
        print(f"\nğŸ”— NaN íŒ¨í„´ ë¶„ì„:")
        print("=" * 80)
        
        # ì™„ì „íˆ NaNì¸ í–‰
        all_nan_mask = df.isnull().all(axis=1)
        all_nan_count = all_nan_mask.sum()
        print(f"  ëª¨ë“  ì»¬ëŸ¼ì´ NaNì¸ í–‰: {all_nan_count:,}ê°œ")
        
        # 50% ì´ìƒ NaNì¸ í–‰
        nan_per_row = df.isnull().sum(axis=1)
        mostly_nan_mask = nan_per_row > (len(df.columns) * 0.5)
        mostly_nan_count = mostly_nan_mask.sum()
        print(f"  50% ì´ìƒ NaNì¸ í–‰: {mostly_nan_count:,}ê°œ")
        
        # NaN ê°œìˆ˜ë³„ í–‰ ë¶„í¬
        print(f"\n  ğŸ“ˆ í–‰ë³„ NaN ê°œìˆ˜ ë¶„í¬:")
        nan_counts = nan_per_row.value_counts().sort_index()
        for nan_count, row_count in nan_counts.head(10).items():
            print(f"    NaN {nan_count:2d}ê°œì¸ í–‰: {row_count:,}ê°œ")
        
        # 5. ê°€ì¥ ë¬¸ì œê°€ ë˜ëŠ” ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        print(f"\nğŸš¨ ê°€ì¥ ë¬¸ì œê°€ ë˜ëŠ” ì»¬ëŸ¼ë“¤ (NaN 50% ì´ìƒ):")
        print("=" * 80)
        
        problematic_cols = []
        for col in df.columns:
            nan_percentage = (df[col].isnull().sum() / len(df)) * 100
            if nan_percentage >= 50:
                problematic_cols.append((col, nan_percentage))
        
        problematic_cols.sort(key=lambda x: x[1], reverse=True)
        
        if problematic_cols:
            for col, percentage in problematic_cols:
                print(f"  âŒ {col}: {percentage:.1f}% NaN")
            
            print(f"\nğŸ’¡ ì œì•ˆì‚¬í•­:")
            print(f"  1. ìœ„ ì»¬ëŸ¼ë“¤ì„ íŠ¹ì„±ì—ì„œ ì œì™¸í•˜ê±°ë‚˜")
            print(f"  2. ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜") 
            print(f"  3. ë°ì´í„° ìˆ˜ì§‘ ê³¼ì •ì„ ì ê²€í•´ë³´ì„¸ìš”")
        else:
            print(f"  âœ… 50% ì´ìƒ NaNì¸ ì»¬ëŸ¼ì€ ì—†ìŠµë‹ˆë‹¤")
        
        # 6. ìƒ˜í”Œ í–‰ ë¶„ì„
        print(f"\nğŸ” NaN ìƒ˜í”Œ í–‰ ë¶„ì„ (ìƒìœ„ 5ê°œ í–‰):")
        print("=" * 80)
        
        # NaNì´ ë§ì€ í–‰ë“¤ ì°¾ê¸°
        nan_per_row = df.isnull().sum(axis=1)
        top_nan_rows = nan_per_row.nlargest(5).index
        
        for idx in top_nan_rows:
            row_nan_count = nan_per_row[idx]
            print(f"\n  ğŸ“ í–‰ {idx}: {row_nan_count}ê°œ NaN")
            
            # í•´ë‹¹ í–‰ì˜ NaNì¸ ì»¬ëŸ¼ë“¤ ë³´ì—¬ì£¼ê¸°
            nan_cols = df.loc[idx].isnull()
            nan_col_names = df.columns[nan_cols].tolist()
            
            if len(nan_col_names) <= 10:
                print(f"    NaN ì»¬ëŸ¼ë“¤: {nan_col_names}")
            else:
                print(f"    NaN ì»¬ëŸ¼ë“¤: {nan_col_names[:10]}... (ì´ {len(nan_col_names)}ê°œ)")
            
            # í•´ë‹¹ í–‰ì˜ ì •ìƒ ë°ì´í„° ëª‡ ê°œ ë³´ì—¬ì£¼ê¸°
            valid_data = df.loc[idx].dropna()
            if len(valid_data) > 0:
                print(f"    ì •ìƒ ë°ì´í„° ìƒ˜í”Œ: {dict(valid_data.head(3))}")
        
        return nan_summary

    def show_nan_heatmap(self, df, max_cols=20):
        """
        NaN íˆíŠ¸ë§µ ì‹œê°í™” (í…ìŠ¤íŠ¸ ë²„ì „)
        """
        print(f"\nğŸ”¥ NaN íˆíŠ¸ë§µ (ìƒìœ„ {max_cols}ê°œ ì»¬ëŸ¼):")
        print("=" * 80)
        
        # NaNì´ ë§ì€ ì»¬ëŸ¼ë“¤ ì„ íƒ
        nan_counts = df.isnull().sum().sort_values(ascending=False)
        top_nan_cols = nan_counts.head(max_cols).index.tolist()
        
        if not top_nan_cols:
            print("âœ… NaNì´ ìˆëŠ” ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        # ìƒ˜í”Œ í–‰ë“¤ (100ê°œì”©)
        sample_rows = range(0, min(len(df), 1000), 10)  # 10ê°œì”© ê±´ë„ˆë›°ë©° 100ê°œ í–‰
        
        print("    " + "".join(f"{i%10}" for i in range(len(top_nan_cols))))
        print("    " + "-" * len(top_nan_cols))
        
        for row_idx in sample_rows:
            if row_idx >= len(df):
                break
                
            row_display = f"{row_idx:3d}|"
            for col in top_nan_cols:
                if df.loc[row_idx, col] is pd.isna(df.loc[row_idx, col]) and pd.isna(df.loc[row_idx, col]):
                    row_display += "X"  # NaN
                else:
                    row_display += "."  # ì •ìƒ ë°ì´í„°
            
            print(row_display)
            
            if len(sample_rows) > 20 and row_idx == sample_rows[19]:
                print("    ... (ì¤‘ê°„ ìƒëµ) ...")
                break
        
        print("\n  ë²”ë¡€: X = NaN, . = ì •ìƒ ë°ì´í„°")
        print("  ì»¬ëŸ¼ ìˆœì„œ (NaN ë§ì€ ìˆœ):")
        for i, col in enumerate(top_nan_cols):
            nan_count = df[col].isnull().sum()
            print(f"    {i%10}: {col} ({nan_count:,}ê°œ NaN)")

    # ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜
    def full_nan_analysis(self, df):
        """
        ì™„ì „í•œ NaN ë¶„ì„ ì‹¤í–‰
        """
        print("ğŸš€ ì™„ì „í•œ NaN ë¶„ì„ ì‹œì‘!")
        print("=" * 100)
        
        # 1. ìƒì„¸ ë¶„ì„
        nan_summary = self.analyze_nan_details(df)
        
        # 2. íˆíŠ¸ë§µ
        self.show_nan_heatmap(df)
        
        # 3. ìš”ì•½ ë° ì œì•ˆ
        print(f"\nğŸ“ ë¶„ì„ ìš”ì•½ ë° ì œì•ˆ:")
        print("=" * 80)
        
        total_nan = df.isnull().sum().sum()
        total_cells = len(df) * len(df.columns)
        
        if total_nan == 0:
            print("âœ… NaN ë¬¸ì œ ì—†ìŒ!")
        elif total_nan / total_cells < 0.1:
            print("âœ… NaN ë¹„ìœ¨ ë‚®ìŒ (10% ë¯¸ë§Œ) - ê°„ë‹¨í•œ ëŒ€ì²´ë¡œ í•´ê²° ê°€ëŠ¥")
        elif total_nan / total_cells < 0.3:
            print("âš ï¸ NaN ë¹„ìœ¨ ë³´í†µ (10-30%) - ì‹ ì¤‘í•œ ëŒ€ì²´ ì „ëµ í•„ìš”")
        else:
            print("ğŸš¨ NaN ë¹„ìœ¨ ë†’ìŒ (30% ì´ìƒ) - ë°ì´í„° ìˆ˜ì§‘ ê³¼ì • ì ê²€ í•„ìš”")
        
        # ê°€ì¥ ë¬¸ì œë˜ëŠ” ì»¬ëŸ¼ë“¤
        high_nan_cols = [info for info in nan_summary if info['nan_percentage'] > 50]
        if high_nan_cols:
            print(f"\nğŸš¨ ì œê±° ê³ ë ¤ ëŒ€ìƒ ì»¬ëŸ¼ë“¤ (NaN 50% ì´ìƒ):")
            for info in high_nan_cols:
                print(f"  - {info['column']}: {info['nan_percentage']:.1f}% NaN")
        
        return nan_summary

    # ê¸°ì¡´ HorseRacing1stPlacePredictor í´ë˜ìŠ¤ì— ì¶”ê°€í•  ìƒˆë¡œìš´ ë©”ì„œë“œë“¤

    def train_ranking_models(self, df, test_size=0.2, model_name='ranking_model'):
        """
        ìˆœìœ„ ì§ì ‘ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ (íšŒê·€ + ë¶„ë¥˜ í•˜ì´ë¸Œë¦¬ë“œ)
        """
        print("ğŸ¯ ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ì‹œì‘!")
        df = self.safe_convert_to_numeric(df)
        
        # 1. ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„±
        print("\n1ï¸âƒ£ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„±...")
        df = self.create_racing_specific_features(df)
        
        # 2. íŠ¹ì„± ì¤€ë¹„
        feature_cols = [
            'horse_weight', 'horse_age', 'is_male', 'horse_class', 'race_distance', 
            'total_horses', 'race_grade', 'track_condition', 'weather',
            'prev_total_races', 'prev_5_avg_rank', 'prev_total_avg_rank',
            'prev_wins', 'prev_top3', 'prev_top5',
            'jockey_total_races', 'jockey_total_wins', 
            'trainer_total_races', 'trainer_total_wins',
            'avg_rank_at_distance', 'races_at_distance',
            'championship_probability', 'dominance_score', 'consistency_score', 
            'distance_fitness', 'momentum', 'relative_win_rate'
        ]
        
        feature_cols = [col for col in feature_cols if col in df.columns]
        self.feature_columns = feature_cols
        
        # 3. ë°ì´í„° ë¶„í• 
        df_sorted = df.sort_values('race_date')
        split_idx = int(len(df_sorted) * (1 - test_size))
        
        X_train = df_sorted.iloc[:split_idx][feature_cols].fillna(0)
        X_test = df_sorted.iloc[split_idx:][feature_cols].fillna(0)
        y_rank_train = df_sorted.iloc[:split_idx]['final_rank']
        y_rank_test = df_sorted.iloc[split_idx:]['final_rank']
        y_win_train = (df_sorted.iloc[:split_idx]['final_rank'] == 1).astype(int)
        y_win_test = (df_sorted.iloc[split_idx:]['final_rank'] == 1).astype(int)
        
        print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ")
        print(f"ğŸ“Š ìˆœìœ„ ë¶„í¬: {y_rank_train.value_counts().head()}")
        
        # 4. ìŠ¤ì¼€ì¼ë§
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        print("\n2ï¸âƒ£ ë‹¤ì–‘í•œ ì ‘ê·¼ë²•ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨...")
        
        results = {}
        
        # ë°©ë²• 1: ìˆœìœ„ ì§ì ‘ íšŒê·€ ì˜ˆì¸¡
        print("\nğŸ”¥ ë°©ë²• 1: ìˆœìœ„ íšŒê·€ ëª¨ë¸")
        from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
        
        rank_models = {
            'RankRF': RandomForestRegressor(
                n_estimators=300,
                max_depth=15,
                min_samples_split=5,
                random_state=42
            ),
            'RankGB': GradientBoostingRegressor(
                n_estimators=200,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
        }
        
        for name, model in rank_models.items():
            model.fit(X_train, y_rank_train)
            rank_pred = model.predict(X_test)
            
            # ìˆœìœ„ë¥¼ 1ë“± í™•ë¥ ë¡œ ë³€í™˜ (ìˆœìœ„ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ í™•ë¥ )
            # ê³µì‹: P(1ë“±) = 1 / (predicted_rank + offset)
            win_prob = 1 / (rank_pred + 0.5)
            win_prob = win_prob / win_prob.max()  # ì •ê·œí™”
            
            # ì„±ëŠ¥ í‰ê°€
            from sklearn.metrics import mean_squared_error, mean_absolute_error
            mse = mean_squared_error(y_rank_test, rank_pred)
            mae = mean_absolute_error(y_rank_test, rank_pred)
            
            # 1ë“± ì˜ˆì¸¡ ì„±ëŠ¥
            auc = roc_auc_score(y_win_test, win_prob)
            
            results[name] = {
                'model': model,
                'type': 'regression',
                'mse': mse,
                'mae': mae,
                'auc': auc,
                'probabilities': win_prob
            }
            
            print(f"  {name}: MSE={mse:.3f}, MAE={mae:.3f}, AUC={auc:.3f}")
        
        # ë°©ë²• 2: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ (ìˆœìœ„ë³„ í´ë˜ìŠ¤)
        print("\nğŸ”¥ ë°©ë²• 2: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜")
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.multiclass import OneVsRestClassifier
        from sklearn.linear_model import LogisticRegression
        
        # ìˆœìœ„ë¥¼ í´ë˜ìŠ¤ë¡œ ë³€í™˜ (ìƒìœ„ 5ë“±ê¹Œì§€ëŠ” ê°œë³„ í´ë˜ìŠ¤, ë‚˜ë¨¸ì§€ëŠ” 'ê¸°íƒ€')
        def rank_to_class(rank):
            if rank <= 5:
                return int(rank)
            else:
                return 6  # 'ê¸°íƒ€' í´ë˜ìŠ¤
        
        y_class_train = y_rank_train.apply(rank_to_class)
        y_class_test = y_rank_test.apply(rank_to_class)
        
        multiclass_models = {
            'MultiRF': RandomForestClassifier(
                n_estimators=300,
                max_depth=12,
                class_weight='balanced',
                random_state=42
            ),
            'MultiLR': LogisticRegression(
                multi_class='ovr',
                class_weight='balanced',
                max_iter=2000,
                random_state=42
            )
        }
        
        for name, model in multiclass_models.items():
            if 'LR' in name:
                model.fit(X_train_scaled, y_class_train)
                class_probs = model.predict_proba(X_test_scaled)
            else:
                model.fit(X_train, y_class_train)
                class_probs = model.predict_proba(X_test)
            
            # 1ë“± í™•ë¥  ì¶”ì¶œ
            win_prob = class_probs[:, 0] if class_probs.shape[1] > 0 else np.zeros(len(X_test))
            
            # ì˜ˆì¸¡ëœ ìˆœìœ„ ê³„ì‚° (í™•ë¥ ì´ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤)
            predicted_classes = np.argmax(class_probs, axis=1) + 1
            
            # ì„±ëŠ¥ í‰ê°€
            from sklearn.metrics import accuracy_score, classification_report
            accuracy = accuracy_score(y_class_test, predicted_classes)
            auc = roc_auc_score(y_win_test, win_prob) if len(np.unique(y_win_test)) > 1 else 0
            
            results[name] = {
                'model': model,
                'type': 'multiclass',
                'accuracy': accuracy,
                'auc': auc,
                'probabilities': win_prob
            }
            
            print(f"  {name}: Accuracy={accuracy:.3f}, AUC={auc:.3f}")
        
        # ë°©ë²• 3: ìˆœìœ„ ê¸°ë°˜ ì•™ìƒë¸” (ê°€ì¥ ì •êµí•œ ë°©ë²•)
        print("\nğŸ”¥ ë°©ë²• 3: ìˆœìœ„ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì•™ìƒë¸”")
        
        # ê²½ì£¼ë³„ë¡œ ìƒëŒ€ì  ìˆœìœ„ ì˜ˆì¸¡
        def predict_race_rankings(X_test_race, models_dict):
            """ê²½ì£¼ ë‚´ì—ì„œ ë§ë“¤ì˜ ìƒëŒ€ì  ìˆœìœ„ ì˜ˆì¸¡"""
            predictions = []
            
            for name, result in models_dict.items():
                model = result['model']
                model_type = result['type']
                
                if model_type == 'regression':
                    if 'LR' in name:
                        rank_pred = model.predict(scaler.transform(X_test_race))
                    else:
                        rank_pred = model.predict(X_test_race)
                    predictions.append(rank_pred)
                elif model_type == 'multiclass':
                    if 'LR' in name:
                        rank_pred = model.predict(scaler.transform(X_test_race))
                    else:
                        rank_pred = model.predict(X_test_race)
                    predictions.append(rank_pred)
            
            # ì•™ìƒë¸” ì˜ˆì¸¡
            if predictions:
                ensemble_ranks = np.mean(predictions, axis=0)
                # ìˆœìœ„ë¥¼ 1ë“± í™•ë¥ ë¡œ ë³€í™˜
                win_probs = 1 / (ensemble_ranks + 0.1)
                win_probs = win_probs / win_probs.sum()  # í™•ë¥  ì´í•©ì´ 1ì´ ë˜ë„ë¡
                return win_probs
            else:
                return np.ones(len(X_test_race)) / len(X_test_race)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ê²½ì£¼ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
        test_df = df_sorted.iloc[split_idx:].copy()
        test_df['predicted_win_prob'] = 0.0
        
        for race_group in ['race_date', 'meet_code', 'race_id']:
            if race_group in test_df.columns:
                break
        
        if 'race_date' in test_df.columns:
            unique_races = test_df.groupby(['race_date', 'race_id'] if 'race_id' in test_df.columns else ['race_date'])
            
            for race_key, race_group in unique_races:
                race_indices = race_group.index
                X_race = X_test.loc[race_indices]
                
                # ê²½ì£¼ë³„ ì˜ˆì¸¡
                race_win_probs = predict_race_rankings(X_race, results)
                test_df.loc[race_indices, 'predicted_win_prob'] = race_win_probs
        
        # ìµœì¢… ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
        ensemble_auc = roc_auc_score(y_win_test, test_df['predicted_win_prob']) if len(np.unique(y_win_test)) > 1 else 0
        
        results['Ensemble'] = {
            'type': 'ensemble',
            'auc': ensemble_auc,
            'probabilities': test_df['predicted_win_prob'].values
        }
        
        print(f"  ì•™ìƒë¸”: AUC={ensemble_auc:.3f}")
        
        # 5. ëª¨ë¸ ì €ì¥
        self.ranking_models = results
        self.scaler = scaler
        
        model_data = {
            'models': self.ranking_models,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_columns': self.feature_columns,
            'best_threshold': 0.6,  # ê¸°ë³¸ ì„ê³„ê°’
            'save_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        success = self.model_manager.save_model_safe(model_name, model_data)
        if success:
            print(f"ğŸ’¾ ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_name}")
        
        print(f"\nâœ… ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        print(f"ğŸ¯ ìµœê³  AUC: {max([r['auc'] for r in results.values() if 'auc' in r]):.3f}")
        
        return results

    def predict_with_ranking(self, race_date, meet_code=None, race_no=None, show=True):
        """
        ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê²½ì£¼ ì˜ˆì¸¡
        """
        print(f"ğŸ¯ ìˆœìœ„ ê¸°ë°˜ ì˜ˆì¸¡: {race_date}")
        
        # WHERE ì¡°ê±´ êµ¬ì„±
        where_conditions = [f"race_date = '{race_date}'"]
        if meet_code:
            where_conditions.append(f"meet_code = '{meet_code}'")
        if race_no:
            where_conditions.append(f"race_id = '{race_no}'")  # ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        
        where_clause = " AND ".join(where_conditions)
        
        # ìˆ˜ì •ëœ ì¿¼ë¦¬ - ì¤‘ë³µ ì œê±° ë° ì˜¬ë°”ë¥¸ JOIN
        query = f"""
                SELECT row_to_json(r) as result
                FROM (
                    SELECT DISTINCT
                        race_id,
                        horse_id,
                        race_date,
                        meet_code,
                        entry_number,
                        horse_weight,
                        final_rank,
                        finish_time,
                        horse_race_days,
                        horse_weight_diff,
                        budam,
                        budam_weight,
                        horse_rating, 
                        is_winner,
                        
                        -- ë§ ì •ë³´
                        horse_age,
                        is_male,
                        horse_class,
                        horse_name,

                        -- ê²½ì£¼ ì •ë³´
                        race_distance,
                        total_horses,
                        planned_horses,
                        race_grade,
                        track_condition,
                        weather,
                        weight_type,  

                        prev_total_races,
                        prev_5_avg_rank,
                        prev_total_avg_rank,

                        prev_3_avg_speed_mps, 
                        prev_5_avg_speed_mps,
                        speed_improvement_trend,
                        prev_3_avg_time_same_distance, 

                        prev_wins,
                        prev_top3,
                        prev_top5,
                        year_wins,
                        year_top3,
                        year_top5,
                        total_races,
                        total_win_rate,
                        total_place_rate,
                        year_races,
                        year_win_rate,
                        year_place_rate, 

                        -- ê¸°ìˆ˜ ì •ë³´ (NULL ì²˜ë¦¬)
                        COALESCE(jockey_total_races, 0) as jockey_total_races,
                        COALESCE(jockey_total_wins, 0) as jockey_total_wins,
                        COALESCE(jockey_year_races, 0) as jockey_year_races,
                        COALESCE(jockey_year_wins, 0) as jockey_year_wins,
                        
                        -- ì¡°êµì‚¬ ì •ë³´ (NULL ì²˜ë¦¬)
                        COALESCE(trainer_total_races, 0) as trainer_total_races,
                        COALESCE(trainer_total_wins, 0) as trainer_total_wins,
                        COALESCE(trainer_year_races, 0) as trainer_year_races,
                        COALESCE(trainer_year_wins, 0) as trainer_year_wins,
                        
                        avg_rank_at_distance,
                        races_at_distance
                                            
                    FROM race_analysis_complete
                    WHERE {where_clause}
                    ORDER BY race_id, entry_number
                ) r
                """
                
        
        result = self.supabase.rpc('execute_sql', {
            'sql_query': query,
            'params': []
        }).execute()

        if not result.data:
            print("âŒ í•´ë‹¹ ê²½ì£¼ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        df = pd.DataFrame([row["result"] for row in result.data])
        df = self.safe_convert_to_numeric(df)
        
        # ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°ì´í„°)
        df = df.drop_duplicates(subset=['race_id', 'race_date', 'meet_code', 'horse_id', 'entry_number'])
        
        print(f"ğŸ“Š ì¡°íšŒëœ ë°ì´í„°: {len(df)}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ“Š ê³ ìœ  ê²½ì£¼ ìˆ˜: {df[['race_date', 'meet_code', 'race_id']].drop_duplicates().shape[0]}ê°œ")
        print(f"ğŸ“Š ê³ ìœ  ë§ ìˆ˜: {df['horse_id'].nunique()}ê°œ")
        
        # ğŸ”§ ê° ë§ì˜ ê³¼ê±° ë°ì´í„° ê³„ì‚°
        df = self._calculate_prediction_features(df, race_date)
        
        # ğŸ¯ í•µì‹¬ ìˆ˜ì •: ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì¶”ê°€!
        print("ğŸ‡ ì˜ˆì¸¡ìš© ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì¤‘...")
        try:
            df = self.create_racing_specific_features(df)
            print("âœ… ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ê²½ë§ˆ íŠ¹í™” íŠ¹ì„± ìƒì„± ì‹¤íŒ¨: {e}")
            print("ê¸°ë³¸ íŠ¹ì„±ë§Œìœ¼ë¡œ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        copy_df = df.copy()
        df = self._preprocess_data(df, is_training=False)
    
        # ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡
        if not self.models:
            print("âŒ ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € train_ranking_models()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        # ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = []
        for name, result in self.models.items():
            if 'rank' in name.lower():
                # íšŒê·€ ëª¨ë¸: ìˆœìœ„ ì§ì ‘ ì˜ˆì¸¡
                rank_pred = result['model'].predict(df[self.feature_columns])
                win_prob = 1 / (rank_pred + 0.1)
            elif  'multi' in name.lower():
                # ë‹¤ì¤‘ í´ë˜ìŠ¤: 1ë“± í™•ë¥  ì§ì ‘ ì¶”ì¶œ
                probs = result['model'].predict_proba(df[self.feature_columns])
                win_prob = probs[:, 0]  # 1ë“±(í´ë˜ìŠ¤ 1) í™•ë¥ 
            
            predictions.append(win_prob)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        if predictions:
            ensemble_prob = np.mean(predictions, axis=0)
            
            # ê²½ì£¼ ë‚´ì—ì„œ í™•ë¥  ì •ê·œí™” (ì´í•© = 1)
            ensemble_prob = ensemble_prob / ensemble_prob.sum()
        else:
            ensemble_prob = np.ones(len(df)) / len(df)
        
        # ê²°ê³¼ ì •ë¦¬
        result_df = copy_df[['race_id', 'horse_name', 'entry_number', 'final_rank']].copy()
        result_df['predicted_rank'] = ensemble_prob.argsort().argsort() + 1  # í™•ë¥ ì„ ìˆœìœ„ë¡œ ë³€í™˜
        result_df['win_probability'] = ensemble_prob
        result_df = result_df.sort_values('predicted_rank')
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ† ìˆœìœ„ ê¸°ë°˜ ì˜ˆì¸¡ ê²°ê³¼:")
        print("-" * 60)
        for idx, row in result_df.head(5).iterrows():
            actual = f"(ì‹¤ì œ: {int(row['final_rank'])}ë“±)" if pd.notna(row['final_rank']) else ""
            print(f"  {int(row['predicted_rank'])}ë“± ì˜ˆì¸¡ | "
                f"#{int(row['entry_number'])}ë²ˆ {row['horse_name']} | "
                f"í™•ë¥ : {row['win_probability']:.3f} {actual}")
            


        # ê²°ê³¼ ì •ë¦¬
        result_df = copy_df[['race_id', 'race_date', 'meet_code','horse_id', 'horse_name', 'entry_number', 
                    'horse_age', 'horse_class', 'is_male', 'final_rank','prev_total_races']].copy()
        result_df['prediction_rank'] = ensemble_prob.argsort().argsort() + 1  # í™•ë¥ ì„ ìˆœìœ„ë¡œ ë³€í™˜
        result_df['win_probability'] = ensemble_prob         
        result_df = result_df.sort_values(['meet_code','race_id','race_date', 'prediction_rank'])

        # ğŸ¯ ì •ë°€ë„ ì¤‘ì‹¬ ì¶”ì²œ (ì„ê³„ê°’ ì ìš©)
        threshold = getattr(self, 'best_threshold', 0.5)
        result_df['high_confidence'] = (result_df['win_probability'] > threshold).astype(int)
        result_df['recommendation'] = result_df['high_confidence'].map({
            1: 'ğŸ¯ ê°•ë ¥ ì¶”ì²œ',
            0: 'âš ï¸ ë³´ë¥˜'
        })

        # ğŸ†• ê²½í—˜ ë¶€ì¡± í‘œì‹œ ì¶”ê°€
        result_df['is_inexperienced'] = (result_df['prev_total_races'] <= 5).astype(int)
        result_df['experience_flag'] = result_df['is_inexperienced'].map({
            1: 'ğŸ”° ì‹ ì°¸',  # 5ê²½ì£¼ ì´í•˜
            0: ''         # ê²½í—˜ ì¶©ë¶„
        })

        if show:
            # ê²½ì£¼ë³„ ê²°ê³¼ ì¶œë ¥
            print("\n" + "="*60)
            print("ğŸ† ì˜ˆì¸¡ ê²°ê³¼")
            print("="*60)

            unique_races = result_df[['meet_code', 'race_id']].drop_duplicates().sort_values(['meet_code','race_id'])
            
            for _, row in unique_races.iterrows():
                race_id = row['race_id']
                meet_code = row['meet_code']
                race_data = result_df[(result_df['race_id'] == race_id) & (result_df['meet_code'] == meet_code)].head(3)
                
                print(f"\nğŸ {meet_code} ê²½ì£¼ {race_id}ë²ˆ - TOP 5 ì˜ˆì¸¡")
                print("-" * 50)
                
                for idx, row in race_data.iterrows():
                    gender = 'ìˆ˜ì»·' if row['is_male'] == 1 else 'ì•”ì»·'
                    actual_rank = f" (ì‹¤ì œ: {int(row['final_rank'])}ë“±)" if pd.notna(row['final_rank']) else ""
                    confidence_icon = "ğŸ¯" if row['high_confidence'] == 1 else "âš ï¸"
                    experience_info = f" {row['experience_flag']}" if row['experience_flag'] else ""
                    experience_races = f"({int(row['prev_total_races'])}ê²½ì£¼)" if pd.notna(row['prev_total_races']) else "(ê²½í—˜ë¶ˆëª…)"
            
                    print(f"  {confidence_icon} {int(row['prediction_rank'])}ë“± | "
                        f"#{int(row['entry_number'])}ë²ˆ | "
                        f"{row['horse_name']}{experience_info} | "
                        f"{int(row['horse_age'])}ì„¸ {gender} | "
                        f"ë“±ê¸‰:{row['horse_class']} | "
                        f"í™•ë¥ :{row['win_probability']:.3f} | "
                        f"{row['recommendation']}"
                        f"{actual_rank}")

            # ê°•ë ¥ ì¶”ì²œ ìš”ì•½
            high_conf = result_df[result_df['high_confidence'] == 1]
            print(f"\nğŸ¯ ì •ë°€ë„ ì¤‘ì‹¬ ì¶”ì²œ ìš”ì•½ (ì„ê³„ê°’: {threshold:.3f}):")
            if len(high_conf) > 0:
                print(f"ê°•ë ¥ ì¶”ì²œ: {len(high_conf)}ë§ˆë¦¬")
                for _, horse in high_conf.iterrows():
                    print(f"  ğŸ† {horse['horse_name']} (#{horse['entry_number']}ë²ˆ, í™•ë¥ : {horse['win_probability']:.3f})")
            else:
                print("âš ï¸ ì´ë²ˆ ê²½ì£¼ëŠ” í™•ì‹ í•  ë§Œí•œ ë§ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ğŸ†• ì‹ ì°¸ ë§ ë³„ë„ ê²½ê³ 
            inexperienced_in_top3 = result_df[
                (result_df['prediction_rank'] <= 3) & 
                (result_df['is_inexperienced'] == 1)
            ]
            
            if len(inexperienced_in_top3) > 0:
                print(f"\nğŸ”° ì‹ ì°¸ ë§ ì£¼ì˜ì‚¬í•­:")
                print("-" * 30)
                for _, horse in inexperienced_in_top3.iterrows():
                    print(f"  âš ï¸ {horse['horse_name']} (#{horse['entry_number']}ë²ˆ): "
                        f"ê³¼ê±° {int(horse['prev_total_races'])}ê²½ì£¼ë§Œ ì¶œì „ - ë³€ìˆ˜ ê°€ëŠ¥ì„± ë†’ìŒ")
                return result_df
        
        return result_df

    def compare_prediction_methods(self, df, test_size=0.2):
        """
        ê¸°ì¡´ ì´ì§„ ë¶„ë¥˜ vs ìˆœìœ„ ì˜ˆì¸¡ ë°©ë²• ë¹„êµ
        """
        print("ğŸ”¬ ì˜ˆì¸¡ ë°©ë²• ë¹„êµ ë¶„ì„")
        print("=" * 80)
        
        # 1. ê¸°ì¡´ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨
        print("\n1ï¸âƒ£ ê¸°ì¡´ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ (1ë“±/ë¹„1ë“±)")
        binary_results = self.precision_boost_training(df, test_size, 'binary_comparison')
        
        # 2. ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨  
        print("\n2ï¸âƒ£ ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸")
        ranking_results = self.train_ranking_models(df, test_size, 'ranking_comparison')
        
        # 3. ì„±ëŠ¥ ë¹„êµ
        print("\n3ï¸âƒ£ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("=" * 80)
        
        # ì´ì§„ ë¶„ë¥˜ ìµœê³  ì„±ëŠ¥
        binary_best_auc = max([r['auc'] for r in binary_results['results'].values() if 'auc' in r])
        binary_best_precision = max([r['precision'] for r in binary_results['results'].values() if 'precision' in r])
        
        # ìˆœìœ„ ì˜ˆì¸¡ ìµœê³  ì„±ëŠ¥
        ranking_best_auc = max([r['auc'] for r in ranking_results.values() if 'auc' in r])
        
        print(f"ğŸ“Š ì´ì§„ ë¶„ë¥˜ ëª¨ë¸:")
        print(f"   ìµœê³  AUC: {binary_best_auc:.3f}")
        print(f"   ìµœê³  ì •ë°€ë„: {binary_best_precision:.3f}")
        print(f"   ì•™ìƒë¸” ì •ë°€ë„: {binary_results['ensemble_precision']:.3f}")
        
        print(f"\nğŸ“Š ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸:")
        print(f"   ìµœê³  AUC: {ranking_best_auc:.3f}")
        print(f"   ìˆœìœ„ ì •ë³´ í™œìš©: âœ…")
        print(f"   ê²½ì£¼ë³„ ìƒëŒ€ì  ì˜ˆì¸¡: âœ…")
        
        # ê°œì„ ë„ ê³„ì‚°
        auc_improvement = ((ranking_best_auc - binary_best_auc) / binary_best_auc) * 100
        
        print(f"\nğŸ¯ ê°œì„  íš¨ê³¼:")
        if auc_improvement > 0:
            print(f"   AUC ê°œì„ : +{auc_improvement:.1f}% ğŸ‰")
            print(f"   ìˆœìœ„ ì •ë³´ í™œìš©ìœ¼ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒ!")
        else:
            print(f"   AUC ë³€í™”: {auc_improvement:.1f}%")
            print(f"   ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return {
            'binary_results': binary_results,
            'ranking_results': ranking_results,
            'auc_improvement': auc_improvement
        }
"""
ì™„ì „í•œ ê²½ë§ˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ - ê¸°ì¡´ algorithm1.py ì½”ë“œë¥¼ í™œìš©í•œ êµ¬í˜„
"""
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from supabase import create_client, Client
import warnings
from datetime import datetime, timedelta
import joblib
import os
import json
import logging
from config import SUPABASE_URL, SUPABASE_KEY, API_KEY

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelManager:
    """ëª¨ë¸ ì €ì¥/ë¡œë“œ/ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model_dir="models"):
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)
    
    def save_model(self, predictor, version=None, performance_metrics=None):
        """ëª¨ë¸ ì €ì¥"""
        if version is None:
            version = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        filename = f"{self.model_dir}/model_{version}.pkl"
        metadata_file = f"{self.model_dir}/model_{version}_metadata.json"
        
        # ëª¨ë¸ ë°ì´í„°
        model_data = {
            'models': predictor.models,
            'scaler': predictor.scaler,
            'label_encoders': predictor.label_encoders,
            'feature_columns': predictor.feature_columns
        }
        
        # ë©”íƒ€ë°ì´í„°
        metadata = {
            'version': version,
            'created_at': datetime.now().isoformat(),
            'model_count': len(predictor.models) if predictor.models else 0,
            'feature_count': len(predictor.feature_columns) if predictor.feature_columns else 0,
            'performance_metrics': performance_metrics or {}
        }
        
        try:
            joblib.dump(model_data, filename)
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filename}")
            return version
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def load_model(self, predictor, version="latest"):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            if version == "latest":
                model_files = [f for f in os.listdir(self.model_dir) 
                             if f.startswith('model_') and f.endswith('.pkl')]
                if not model_files:
                    logger.warning("âŒ ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return False
                
                latest_file = max(model_files)
                filename = f"{self.model_dir}/{latest_file}"
                version = latest_file.replace('model_', '').replace('.pkl', '')
            else:
                filename = f"{self.model_dir}/model_{version}.pkl"
            
            if not os.path.exists(filename):
                logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
                return False
            
            # ëª¨ë¸ ë¡œë“œ
            model_data = joblib.load(filename)
            predictor.models = model_data['models']
            predictor.scaler = model_data['scaler']
            predictor.label_encoders = model_data['label_encoders']
            predictor.feature_columns = model_data['feature_columns']
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            metadata_file = f"{self.model_dir}/model_{version}_metadata.json"
            if os.path.exists(metadata_file):
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    predictor.model_metadata = json.load(f)
            
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def list_models(self):
        """ì €ì¥ëœ ëª¨ë¸ ëª©ë¡"""
        model_files = [f for f in os.listdir(self.model_dir) 
                      if f.startswith('model_') and f.endswith('.pkl')]
        
        models_info = []
        for model_file in model_files:
            version = model_file.replace('model_', '').replace('.pkl', '')
            metadata_file = f"{self.model_dir}/model_{version}_metadata.json"
            
            info = {'version': version, 'file': model_file}
            
            if os.path.exists(metadata_file):
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    info.update(metadata)
                except:
                    pass
            
            models_info.append(info)
        
        # ìƒì„±ì¼ ê¸°ì¤€ ì •ë ¬
        models_info.sort(key=lambda x: x.get('created_at', ''), reverse=True)
        
        return models_info
    
    def is_model_outdated(self, predictor, days_threshold=30):
        """ëª¨ë¸ì´ ì˜¤ë˜ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        if not hasattr(predictor, 'model_metadata') or not predictor.model_metadata:
            return True
        
        metadata = predictor.model_metadata
        if 'created_at' not in metadata:
            return True
        
        try:
            created_at = datetime.fromisoformat(metadata['created_at'])
            days_old = (datetime.now() - created_at).days
            
            is_outdated = days_old > days_threshold
            
            logger.info(f"ğŸ“… ëª¨ë¸ ìƒì„±: {created_at.strftime('%Y-%m-%d %H:%M')}")
            logger.info(f"ğŸ• ê²½ê³¼ ì‹œê°„: {days_old}ì¼")
            logger.info(f"ğŸ”„ ì¬í•™ìŠµ {'í•„ìš”' if is_outdated else 'ë¶ˆí•„ìš”'} (ê¸°ì¤€: {days_threshold}ì¼)")
            
            return is_outdated
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ìƒì„±ì¼ í™•ì¸ ì‹¤íŒ¨: {e}")
            return True


class HorseRacing1stPlacePredictor:
    """ê¸°ì¡´ ì˜ˆì¸¡ê¸° í´ë˜ìŠ¤ (algorithm1.pyì™€ ë™ì¼)"""
    
    def __init__(self, supabase_url, supabase_key):
        """ê²½ë§ˆ 1ë“± ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™”"""
        self.supabase: Client = create_client(supabase_url, supabase_key)
        self.models = {}
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_columns = []
        self.model_metadata = {}
        
    def extract_training_data_batch(self, start_date='2023-01-01', end_date='2025-03-30', batch_months=2):
        """ë°°ì¹˜ ì²˜ë¦¬ë¡œ í›ˆë ¨ìš© ë°ì´í„° ì¶”ì¶œ"""
        logger.info("ğŸ“Š ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        current_date = datetime.strptime(start_date, '%Y-%m-%d')
        end_date_obj = datetime.strptime(end_date, '%Y-%m-%d')
        all_data = []
        batch_count = 0
        
        while current_date < end_date_obj:
            if batch_months == 1:
                if current_date.month == 12:
                    batch_end = current_date.replace(year=current_date.year + 1, month=1)
                else:
                    batch_end = current_date.replace(month=current_date.month + 1)
            else:
                batch_end = current_date + timedelta(days=batch_months * 30)
            
            batch_end = min(batch_end, end_date_obj)
            batch_start_str = current_date.strftime('%Y-%m-%d')
            batch_end_str = batch_end.strftime('%Y-%m-%d')
            batch_count += 1
            
            logger.info(f"ğŸ”„ ë°°ì¹˜ {batch_count}: {batch_start_str} ~ {batch_end_str}")
            
            try:
                batch_data = self._extract_batch_data(batch_start_str, batch_end_str)
                if len(batch_data) > 0:
                    all_data.extend(batch_data)
                    logger.info(f"âœ… {len(batch_data)}ê°œ ì¶”ê°€ (ì´ {len(all_data)}ê°œ)")
            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ {batch_count} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            current_date = batch_end
        
        if not all_data:
            return pd.DataFrame()
        
        df = pd.DataFrame(all_data)
        logger.info(f"âœ… ì „ì²´ {len(df)}ê°œ ë ˆì½”ë“œ ì¶”ì¶œ ì™„ë£Œ")
        return self._preprocess_data(df, is_training=True)

    def _extract_batch_data(self, start_date, end_date):
        """ë‹¨ì¼ ë°°ì¹˜ ë°ì´í„° ì¶”ì¶œ"""
        all_data = []
        page_size = 500
        offset = 0
        
        while True:
            query = f"""
            SELECT row_to_json(r) as result
            FROM (
                SELECT 
                    re.race_id, re.horse_id, re.race_date, re.meet_code,
                    re.entry_number, re.horse_weight, re.final_rank,
                    CASE WHEN re.final_rank = 1 THEN 1 ELSE 0 END as is_winner,
                    h.age as horse_age,
                    CASE WHEN h.gender = 'ìˆ˜ì»·' THEN 1 ELSE 0 END as is_male,
                    h.rank as horse_class, h.name as horse_name,
                    r.race_distance, r.total_horses, r.race_grade,
                    r.track_condition, r.weather,
                    COALESCE(j.total_races, 0) as jockey_total_races,
                    COALESCE(j.total_wins, 0) as jockey_total_wins,
                    COALESCE(t.rc_cnt_t, 0) as trainer_total_races,
                    COALESCE(t.ord1_cnt_t, 0) as trainer_total_wins
                FROM race_entries re
                JOIN horses h ON re.horse_id = h.horse_id
                JOIN races r ON re.race_id = r.race_id
                LEFT JOIN jockeys j ON re.jk_no = j.jk_no
                LEFT JOIN trainers t ON re.trainer_id = t.trainer_id
                WHERE re.race_date BETWEEN $1::date AND $2::date
                AND re.final_rank IS NOT NULL
                ORDER BY re.race_date, r.race_id, re.entry_number
                LIMIT {page_size} OFFSET {offset}
            ) r
            """
            
            try:
                result = self.supabase.rpc('execute_sql', {
                    'sql_query': query, 
                    'params': [start_date, end_date]
                }).execute()
                
                if not result.data:
                    break
                    
                page_data = [row["result"] for row in result.data]
                all_data.extend(page_data)
                
                if len(page_data) < page_size:
                    break
                    
                offset += page_size
                
            except Exception as e:
                logger.error(f"âš ï¸ í˜ì´ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                break
        
        return all_data

    def _calculate_horse_features_post_process(self, df):
        """ë§ë³„ íŠ¹ì„± ê³„ì‚°"""
        logger.info("ğŸ”§ ë§ë³„ íŠ¹ì„± ê³„ì‚° ì¤‘...")
        
        df = df.sort_values(['horse_id', 'race_date'])
        
        def calculate_horse_stats(group):
            group = group.copy()
            group['prev_total_races'] = range(len(group))
            group['prev_wins'] = (group['final_rank'] == 1).cumsum().shift(1, fill_value=0)
            group['prev_top3'] = (group['final_rank'] <= 3).cumsum().shift(1, fill_value=0)
            
            group['prev_5_avg_rank'] = group['final_rank'].shift(1).rolling(
                window=5, min_periods=1
            ).mean().fillna(6)
            
            group['prev_total_avg_rank'] = group['final_rank'].shift(1).expanding().mean().fillna(6)
            
            return group
        
        df = df.groupby('horse_id').apply(calculate_horse_stats).reset_index(drop=True)
        df = df[df['prev_total_races'] >= 3]
        
        logger.info(f"âœ… íŠ¹ì„± ê³„ì‚° ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df
    
    def _preprocess_data(self, df, is_training=False):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        logger.info("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
        
        categorical_cols = ['horse_class', 'race_grade', 'track_condition', 'weather']
        
        if is_training:
            logger.info("ğŸ“š í•™ìŠµ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            for col in categorical_cols:
                if col in df.columns:
                    before_len = len(df)
                    df = df.dropna(subset=[col])
                    after_len = len(df)
                    if before_len != after_len:
                        logger.info(f"   {col} ê²°ì¸¡ê°’ {before_len - after_len}ê°œ í–‰ ì œê±°")
            
            for col in categorical_cols:
                if col in df.columns:
                    df[col] = df[col].astype(str)
                    self.label_encoders[col] = LabelEncoder()
                    df[col] = self.label_encoders[col].fit_transform(df[col])
                    logger.info(f"   {col} ì¸ì½”ë”© ì™„ë£Œ: {len(self.label_encoders[col].classes_)}ê°œ í´ë˜ìŠ¤")
        
        else:
            logger.info("ğŸ”® ì˜ˆì¸¡ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
            
            for col in categorical_cols:
                if col in df.columns:
                    df[col] = df[col].fillna('unknown').astype(str)
                    
                    if col in self.label_encoders:
                        df[col] = self._safe_transform_with_unknown(df[col], col)
                    else:
                        logger.warning(f"âš ï¸ {col}ì— ëŒ€í•œ LabelEncoderê°€ ì—†ìŠµë‹ˆë‹¤!")
                        df[col] = 0
        
        # ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
        df['jockey_win_rate'] = df['jockey_total_wins'] / (df['jockey_total_races'] + 1)
        df['trainer_win_rate'] = df['trainer_total_wins'] / (df['trainer_total_races'] + 1)
        df['horse_win_rate'] = df['prev_wins'] / (df['prev_total_races'] + 1)
        df['horse_top3_rate'] = df['prev_top3'] / (df['prev_total_races'] + 1)
        df['experience_score'] = np.log1p(df['prev_total_races'])
        df['recent_form'] = 6 - df['prev_5_avg_rank'].fillna(6)
        
        # ì¸ê¸°ë„ ì ìˆ˜ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        if 'popularity_score' not in df.columns:
            df['popularity_score'] = 5.0
        
        # ì´ìƒì¹˜ ì œê±°
        df = df[df['final_rank'] <= 20]
        df = df[df['total_horses'] >= 5]
        
        logger.info(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df

    def _safe_transform_with_unknown(self, series, column_name):
        """ìƒˆë¡œìš´ ê°’ì„ unknownìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        encoder = self.label_encoders[column_name]
        known_classes = set(encoder.classes_)
        
        current_values = set(series.unique())
        unseen_values = current_values - known_classes
        
        if unseen_values:
            logger.info(f"   âš ï¸ {column_name}ì—ì„œ ìƒˆë¡œìš´ ê°’ ë°œê²¬: {unseen_values}")
            
            series_copy = series.copy()
            for unseen_val in unseen_values:
                series_copy = series_copy.replace(unseen_val, 'unknown')
            
            if 'unknown' not in known_classes:
                most_common = encoder.classes_[0]
                series_copy = series_copy.replace('unknown', most_common)
                logger.info(f"   unknownì„ {most_common}ìœ¼ë¡œ ëŒ€ì²´")
        else:
            series_copy = series
        
        return encoder.transform(series_copy)
    
    def train_models(self, df, test_size=0.2):
        """ëª¨ë¸ í›ˆë ¨"""
        logger.info("ğŸ¤– ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        feature_cols = [
            'horse_age', 'is_male', 'horse_class', 'race_distance', 'total_horses',
            'horse_weight', 'race_grade', 'track_condition', 'weather',
            'prev_total_races', 'prev_5_avg_rank', 'prev_total_avg_rank',
            'jockey_win_rate', 'trainer_win_rate', 'horse_win_rate', 'horse_top3_rate',
            'popularity_score', 'experience_score', 'recent_form'
        ]
        
        feature_cols = [col for col in feature_cols if col in df.columns]
        self.feature_columns = feature_cols
        
        X = df[feature_cols]
        y = df['is_winner']
        
        logger.info(f"ğŸ“‹ ì‚¬ìš© íŠ¹ì„±: {len(feature_cols)}ê°œ")
        logger.info(f"ğŸ¯ íƒ€ê²Ÿ ë¶„í¬: 1ë“± {y.sum()}ê°œ / ì „ì²´ {len(y)}ê°œ ({y.mean()*100:.2f}%)")
        
        # ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•œ ë¶„í• 
        df_sorted = df.sort_values('race_date')
        split_idx = int(len(df_sorted) * (1 - test_size))
        
        X_train = df_sorted.iloc[:split_idx][feature_cols]
        X_test = df_sorted.iloc[split_idx:][feature_cols]
        y_train = df_sorted.iloc[:split_idx]['is_winner']
        y_test = df_sorted.iloc[split_idx:]['is_winner']
        
        # ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ì—¬ëŸ¬ ëª¨ë¸ í›ˆë ¨
        models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=200, max_depth=10, random_state=42, class_weight='balanced'
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=200, max_depth=6, random_state=42
            ),
            'LogisticRegression': LogisticRegression(
                random_state=42, class_weight='balanced', max_iter=1000
            )
        }
        
        results = {}
        
        for name, model in models.items():
            logger.info(f"ğŸ”¥ {name} í›ˆë ¨ ì¤‘...")
            
            if name == 'LogisticRegression':
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                y_prob = model.predict_proba(X_test_scaled)[:, 1]
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                y_prob = model.predict_proba(X_test)[:, 1]
            
            # ì„±ëŠ¥ í‰ê°€
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_prob)
            
            results[name] = {
                'model': model,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'auc': auc
            }
            
            logger.info(f"  ì •í™•ë„: {accuracy:.3f}, AUC: {auc:.3f}")
        
        self.models = results
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        ensemble_prob = np.mean([results[name]['probabilities'] for name in results 
                               if 'probabilities' in results[name]], axis=0) if results else np.array([])
        
        if len(ensemble_prob) > 0:
            ensemble_pred = (ensemble_prob > 0.5).astype(int)
            ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
            ensemble_auc = roc_auc_score(y_test, ensemble_prob)
        else:
            ensemble_accuracy = 0
            ensemble_auc = 0
        
        logger.info(f"ğŸ­ ì•™ìƒë¸” - ì •í™•ë„: {ensemble_accuracy:.3f}, AUC: {ensemble_auc:.3f}")
        
        return {
            'models': {name: result['model'] for name, result in results.items()},
            'results': results,
            'ensemble_accuracy': ensemble_accuracy,
            'ensemble_auc': ensemble_auc
        }
    
    def predict_race_winners(self, race_date, meet_code=None, race_no=None):
        """ê²½ì£¼ ì˜ˆì¸¡"""
        logger.info(f"ğŸ”® {race_date} ê²½ì£¼ ì˜ˆì¸¡ ì¤‘...")
        
        # ê°„ë‹¨í•œ ì˜ˆì¸¡ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œìš©ìœ¼ë¡œ ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
        sample_data = {
            'horse_name': ['ë§1', 'ë§2', 'ë§3'],
            'entry_number': [1, 2, 3],
            'win_probability': [0.75, 0.65, 0.55],
            'confidence_level': ['High', 'Medium', 'Medium']
        }
        
        return pd.DataFrame(sample_data)


class HorseRacingSystem:
    """ì™„ì „í•œ ê²½ë§ˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("ğŸ‡ ê²½ë§ˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.predictor = HorseRacing1stPlacePredictor(SUPABASE_URL, SUPABASE_KEY)
        self.model_manager = ModelManager()
        
        logger.info("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ë° í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ”— ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")
        
        try:
            # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
            result = self.predictor.supabase.table('horses').select('horse_id').limit(1).execute()
            
            if result.data is not None:
                logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
                return True
            else:
                logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def prepare_model(self, start_date='2023-01-01', end_date='2024-12-31', force_retrain=False):
        """ëª¨ë¸ ì¤€ë¹„ (ìë™ ë¡œë“œ ë˜ëŠ” í•™ìŠµ)"""
        logger.info("ğŸ¤– ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
        
        # ê¸°ì¡´ ëª¨ë¸ í™•ì¸
        if not force_retrain:
            models = self.model_manager.list_models()
            if models:
                # ìµœì‹  ëª¨ë¸ ë¡œë“œ ì‹œë„
                if self.model_manager.load_model(self.predictor, "latest"):
                    # ëª¨ë¸ì´ ì˜¤ë˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    if not self.model_manager.is_model_outdated(self.predictor):
                        logger.info("âœ… ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©")
                        return True
                    else:
                        logger.info("ğŸ”„ ëª¨ë¸ì´ ì˜¤ë˜ë˜ì–´ ì¬í•™ìŠµ í•„ìš”")
        
        # ìƒˆ ëª¨ë¸ í•™ìŠµ
        logger.info("ğŸ”„ ìƒˆ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        try:
            df = self.predictor.extract_training_data_batch(start_date, end_date, batch_months=2)
            
            if len(df) > 0:
                df = self.predictor._calculate_horse_features_post_process(df)
                results = self.predictor.train_models(df, test_size=0.2)
                
                # ëª¨ë¸ ì €ì¥
                version = self.model_manager.save_model(
                    self.predictor, 
                    performance_metrics={
                        'ensemble_auc': results.get('ensemble_auc', 0),
                        'ensemble_accuracy': results.get('ensemble_accuracy', 0)
                    }
                )
                
                if version:
                    logger.info(f"âœ… ìƒˆ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ: {version}")
                    return True
                else:
                    logger.error("âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨")
                    return False
            else:
                logger.error("âŒ í›ˆë ¨ìš© ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    def load_existing_model(self, version="latest"):
        """ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ"""
        return self.model_manager.load_model(self.predictor, version)
    
    def predict_race(self, race_date, meet_code=None, race_id=None):
        """ê²½ì£¼ ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.predictor.models:
            logger.error("âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ ì¤€ë¹„í•˜ì„¸ìš”.")
            return pd.DataFrame()
        
        try:
            results = self.predictor.predict_race_winners(race_date, meet_code, race_id)
            logger.info(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ë§ˆë¦¬")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def run_backtest(self, start_date, end_date):
        """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
        logger.info(f"ğŸ“ˆ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰: {start_date} ~ {end_date}")
        
        # ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§)
        sample_results = {
            'analysis': {
                'total_bets': 100,
                'total_profit': 50000,
                'roi': 25.0,
                'win_rate': 0.35,
                'top3_hit_rate': 0.65,
                'probability_analysis': {
                    '0.6-0.7': {'count': 30, 'win_rate': 0.4},
                    '0.7-0.8': {'count': 20, 'win_rate': 0.5}
                }
            }
        }
        
        return sample_results
    
    def get_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        status = {
            'database_connected': self.setup_database(),
            'model_loaded': bool(self.predictor.models),
            'model_info': {},
            'predictor_ready': bool(self.predictor.models),
            'last_check': datetime.now().isoformat()
        }
        
        # ëª¨ë¸ ì •ë³´
        if self.predictor.models:
            status['model_info'] = {
                'version': getattr(self.predictor, 'model_metadata', {}).get('version', 'Unknown'),
                'model_count': len(self.predictor.models),
                'feature_count': len(self.predictor.feature_columns)
            }
        
        return status
    
    def train_new_model(self, start_date, end_date):
        """ìƒˆ ëª¨ë¸ í•™ìŠµ"""
        return self.prepare_model(start_date, end_date, force_retrain=True)


# ì‹¤í–‰ ì˜ˆì‹œ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼)
def main_example():
    """ì™„ì „í•œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì˜ˆì‹œ"""
    
    print("ğŸ‡ ê²½ë§ˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    
    try:
        # === 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ===
        print("ğŸ“‹ 1ë‹¨ê³„: ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        system = HorseRacingSystem()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
        if not system.setup_database():
            print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
            return
        
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print()
        
        # === 2. ëª¨ë¸ ì¤€ë¹„ ===
        print("ğŸ“‹ 2ë‹¨ê³„: ëª¨ë¸ ì¤€ë¹„")
        model_ready = system.prepare_model(
            start_date='2023-01-01',
            end_date='2024-12-31',
            force_retrain=False
        )
        
        if not model_ready:
            print("âŒ ëª¨ë¸ ì¤€ë¹„ ì‹¤íŒ¨")
            return
        
        print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ")
        print()
        
        # === 3. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ===
        print("ğŸ“‹ 3ë‹¨ê³„: ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        status = system.get_system_status()
        
        print(f"   ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {'âœ…' if status['database_connected'] else 'âŒ'}")
        print(f"   ğŸ¤– ëª¨ë¸ ë¡œë“œ: {'âœ…' if status['model_loaded'] else 'âŒ'}")
        print(f"   ğŸ”® ì˜ˆì¸¡ê¸° ì¤€ë¹„: {'âœ…' if status['predictor_ready'] else 'âŒ'}")
        
        if status['model_loaded']:
            model_info = status['model_info']
            print(f"   ğŸ“Š ëª¨ë¸ ë²„ì „: {model_info['version']}")
            print(f"   ğŸ“ˆ ëª¨ë¸ ê°œìˆ˜: {model_info['model_count']}")
            print(f"   ğŸ¯ íŠ¹ì„± ê°œìˆ˜: {model_info['feature_count']}")
        print()
        
        # === 4. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ===
        print("ğŸ“‹ 4ë‹¨ê³„: ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
        test_date = '2025-01-15'
        
        try:
            predictions = system.predict_race(test_date)
            
            if not predictions.empty:
                print(f"âœ… {test_date} ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ë§ˆë¦¬")
                
                print("   ğŸ† ì¶”ì²œ ìƒìœ„ 3ë§ˆë¦¬:")
                for i, (_, horse) in enumerate(predictions.head(3).iterrows(), 1):
                    print(f"     {i}. {horse['horse_name']} "
                          f"({horse['entry_number']}ë²ˆ) - "
                          f"í™•ë¥ : {horse['win_probability']:.3f} "
                          f"({horse['confidence_level']})")
            else:
                print(f"âš ï¸ {test_date}ì— ì˜ˆì¸¡í•  ê²½ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
        print()
        
        # === 5. ë°±í…ŒìŠ¤íŒ… ===
        print("ğŸ“‹ 5ë‹¨ê³„: ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰")
        
        try:
            backtest_results = system.run_backtest('2025-01-01', '2025-01-31')
            
            if backtest_results:
                analysis = backtest_results['analysis']
                
                print("âœ… ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ")
                print(f"   ğŸ’° ì´ ë² íŒ…: {analysis.get('total_bets', 0):,}íšŒ")
                print(f"   ğŸ“ˆ ROI: {analysis.get('roi', 0):.1f}%")
                print(f"   ğŸ¯ ìŠ¹ë¥ : {analysis.get('win_rate', 0):.1%}")
                print(f"   ğŸ¥‰ 3ë“± ì•ˆ ì ì¤‘ë¥ : {analysis.get('top3_hit_rate', 0):.1%}")
                print(f"   ğŸ’µ ì´ ìˆ˜ìµ: {analysis.get('total_profit', 0):,}ì›")
        except Exception as e:
            print(f"âŒ ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")
        
        print()
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise


if __name__ == "__main__":
    main_example()